{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa7a86b4-2bd2-4cd5-9eab-9b272c3c13fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import brown_clustering\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from brown_clustering import BigramCorpus, BrownClustering\n",
    "from collections import defaultdict\n",
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7feaeb-8b8c-4d8d-b363-9073a0c823a6",
   "metadata": {},
   "source": [
    "# Load NLP Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02868236-43ce-4dde-84a0-eb08ac9b33f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = English()\n",
    "tokenizer = nlp.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b65e10b-0b09-4e7c-8f0a-6a4eed34a59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.Defaults.stop_words |= {'.', ',', '\"', '(', ')', '?', '!', '...', '-', \"'\", '©', '°'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2976ef2-753d-432c-9c87-23c9b22b741d",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae2eb404-8c0d-4c52-bc70-6dac60e0a1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_options = ['language', 'main-idea', 'organization', 'support']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc73301b-e92e-4d0c-aae8-161ac181ed3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language\n",
      "892\n",
      "main-idea\n",
      "1195\n",
      "organization\n",
      "775\n",
      "support\n",
      "583\n"
     ]
    }
   ],
   "source": [
    "datasets = {}\n",
    "for opt in model_options:\n",
    "    print(opt)\n",
    "    datasets[opt] = pd.read_csv(f'{opt}-analysis_set.parsed.csv')\n",
    "    print (len(datasets[opt]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82fbb386-72b6-4cca-9cf5-395406fcae57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tii/america_singing',\n",
       " 'tii/ap_eng_owning_yourself_informative_3_0_0',\n",
       " 'tii/ap_hist_local_and_global_historical_analysis_1_0_0',\n",
       " 'tii/earth_is_cruel_analysis_1_0_0',\n",
       " 'tii/laughter_narrative_3_0_0',\n",
       " 'tii/london_eyes_open_narrative_3_0_0',\n",
       " 'tii/nature_by_design_informative_3_0_0',\n",
       " 'tii/patience_narrative_3_0_0',\n",
       " 'tii/tell_tale_heart_narrative_3_0_0',\n",
       " 'tii/the_giver_analysis_1_0_0',\n",
       " 'tii/tomorrow_seeds_informative_3_0_0',\n",
       " 'tii/uniforms_argumentative_3_0_0'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(datasets['main-idea']['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7f4a134-0efc-40f2-b2ef-28db81c34754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding texts from [language] ... DONE.\n",
      "892\n",
      "Adding texts from [main-idea] ... DONE.\n",
      "1746\n",
      "Adding texts from [organization] ... DONE.\n",
      "1989\n",
      "Adding texts from [support] ... DONE.\n",
      "2277\n"
     ]
    }
   ],
   "source": [
    "all_texts = set()\n",
    "all_prompts = set()\n",
    "for opt in model_options:\n",
    "    print (f\"Adding texts from [{opt}] ... \", end='')\n",
    "    all_texts.update(set(datasets[opt]['text']))\n",
    "    all_prompts.update(set(datasets[opt]['prompt']))\n",
    "    print(\"DONE.\")\n",
    "    print (len(all_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "085cf349-cbf2-4ab5-a1f4-2ed8d75b39c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding texts from [language] ... DONE.\n",
      "12\n",
      "Adding texts from [main-idea] ... DONE.\n",
      "18\n",
      "Adding texts from [organization] ... DONE.\n",
      "19\n",
      "Adding texts from [support] ... DONE.\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "all_texts = defaultdict(set)\n",
    "for opt in model_options:\n",
    "    print (f\"Adding texts from [{opt}] ... \", end='')\n",
    "    for idx, prompt in datasets[opt]['prompt'].items():\n",
    "        all_texts[prompt].add(datasets[opt]['text'].iloc[idx])\n",
    "    print(\"DONE.\")\n",
    "    print (len(all_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b90fc43d-b794-45b3-85c2-e35b07c0bae1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Processing 97 documents for prompt, `tii/ad_me_informative_3_0_0` ... (1 out of 24)\n",
      "Vocab count: 1269\n",
      "Token count: 39786\n",
      "unique 2gram count: 16187\n",
      "2gram count: 39883.0\n",
      "Laplace smoothing: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1269/1269 [00:55<00:00, 22.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Processing 101 documents for prompt, `tii/america_singing` ... (2 out of 24)\n",
      "Vocab count: 1166\n",
      "Token count: 46411\n",
      "unique 2gram count: 13957\n",
      "2gram count: 46512.0\n",
      "Laplace smoothing: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1166/1166 [00:41<00:00, 28.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Processing 37 documents for prompt, `tii/ap_eng_memorialize_argumentative_3_0_0` ... (3 out of 24)\n",
      "Vocab count: 945\n",
      "Token count: 21851\n",
      "unique 2gram count: 9062\n",
      "2gram count: 21888.0\n",
      "Laplace smoothing: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 945/945 [00:28<00:00, 33.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Processing 136 documents for prompt, `tii/ap_eng_owning_yourself_informative_3_0_0` ... (4 out of 24)\n",
      "Vocab count: 1605\n",
      "Token count: 65797\n",
      "unique 2gram count: 22826\n",
      "2gram count: 65933.0\n",
      "Laplace smoothing: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1605/1605 [01:05<00:00, 24.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Processing 161 documents for prompt, `tii/ap_hist_local_and_global_historical_analysis_1_0_0` ... (5 out of 24)\n",
      "Vocab count: 1405\n",
      "Token count: 50919\n",
      "unique 2gram count: 17617\n",
      "2gram count: 51080.0\n",
      "Laplace smoothing: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1405/1405 [00:54<00:00, 25.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Processing 43 documents for prompt, `tii/call_or_text_informative_3_0_0` ... (6 out of 24)\n",
      "Vocab count: 617\n",
      "Token count: 14968\n",
      "unique 2gram count: 6688\n",
      "2gram count: 15011.0\n",
      "Laplace smoothing: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 617/617 [00:11<00:00, 55.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Processing 55 documents for prompt, `tii/earth_is_cruel_analysis_1_0_0` ... (7 out of 24)\n",
      "Vocab count: 1075\n",
      "Token count: 30356\n",
      "unique 2gram count: 11445\n",
      "2gram count: 30411.0\n",
      "Laplace smoothing: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1075/1075 [00:35<00:00, 29.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Processing 9 documents for prompt, `tii/human_language_historical_analysis_1_0_0` ... (8 out of 24)\n",
      "Vocab count: 262\n",
      "Token count: 3982\n",
      "unique 2gram count: 2116\n",
      "2gram count: 3991.0\n",
      "Laplace smoothing: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 262/262 [00:01<00:00, 165.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Processing 68 documents for prompt, `tii/julius_caesar_analysis_1_0_0` ... (9 out of 24)\n",
      "Vocab count: 980\n",
      "Token count: 39686\n",
      "unique 2gram count: 11657\n",
      "2gram count: 39754.0\n",
      "Laplace smoothing: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 980/980 [00:31<00:00, 31.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Processing 55 documents for prompt, `tii/just_because_narrative_3_0_0` ... (10 out of 24)\n",
      "Vocab count: 1118\n",
      "Token count: 27443\n",
      "unique 2gram count: 12346\n",
      "2gram count: 27498.0\n",
      "Laplace smoothing: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1118/1118 [00:37<00:00, 29.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Processing 176 documents for prompt, `tii/laughter_narrative_3_0_0` ... (11 out of 24)\n",
      "Vocab count: 2359\n",
      "Token count: 87303\n",
      "unique 2gram count: 32780\n",
      "2gram count: 87479.0\n",
      "Laplace smoothing: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2359/2359 [01:47<00:00, 21.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Processing 96 documents for prompt, `tii/london_eyes_open_narrative_3_0_0` ... (12 out of 24)\n",
      "Vocab count: 1109\n",
      "Token count: 34308\n",
      "unique 2gram count: 13344\n",
      "2gram count: 34404.0\n",
      "Laplace smoothing: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1109/1109 [00:37<00:00, 29.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Processing 128 documents for prompt, `tii/man_in_the_water_analysis_1_0_0` ... (13 out of 24)\n",
      "Vocab count: 1079\n",
      "Token count: 45441\n",
      "unique 2gram count: 13320\n",
      "2gram count: 45569.0\n",
      "Laplace smoothing: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1079/1079 [00:36<00:00, 29.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Processing 45 documents for prompt, `tii/naps_argumentative_3_0_0` ... (14 out of 24)\n",
      "Vocab count: 893\n",
      "Token count: 26192\n",
      "unique 2gram count: 9797\n",
      "2gram count: 26237.0\n",
      "Laplace smoothing: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 893/893 [00:25<00:00, 34.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Processing 80 documents for prompt, `tii/nature_by_design_informative_3_0_0` ... (15 out of 24)\n",
      "Vocab count: 1221\n",
      "Token count: 43551\n",
      "unique 2gram count: 12756\n",
      "2gram count: 43631.0\n",
      "Laplace smoothing: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1221/1221 [00:43<00:00, 27.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Processing 187 documents for prompt, `tii/patience_narrative_3_0_0` ... (16 out of 24)\n",
      "Vocab count: 1964\n",
      "Token count: 80052\n",
      "unique 2gram count: 27904\n",
      "2gram count: 80239.0\n",
      "Laplace smoothing: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1964/1964 [01:25<00:00, 22.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Processing 49 documents for prompt, `tii/prep_work_argumentative_3_0_0` ... (17 out of 24)\n",
      "Vocab count: 665\n",
      "Token count: 18283\n",
      "unique 2gram count: 7717\n",
      "2gram count: 18332.0\n",
      "Laplace smoothing: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 665/665 [00:13<00:00, 48.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Processing 39 documents for prompt, `tii/social_argumentative_3_0_0` ... (18 out of 24)\n",
      "Vocab count: 594\n",
      "Token count: 11643\n",
      "unique 2gram count: 6092\n",
      "2gram count: 11682.0\n",
      "Laplace smoothing: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 594/594 [00:09<00:00, 59.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Processing 93 documents for prompt, `tii/tell_tale_heart_narrative_3_0_0` ... (19 out of 24)\n",
      "Vocab count: 1302\n",
      "Token count: 41384\n",
      "unique 2gram count: 16045\n",
      "2gram count: 41477.0\n",
      "Laplace smoothing: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1302/1302 [00:48<00:00, 26.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Processing 135 documents for prompt, `tii/the_giver_analysis_1_0_0` ... (20 out of 24)\n",
      "Vocab count: 1388\n",
      "Token count: 57010\n",
      "unique 2gram count: 18460\n",
      "2gram count: 57145.0\n",
      "Laplace smoothing: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1388/1388 [00:53<00:00, 25.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Processing 95 documents for prompt, `tii/tomorrow_seeds_informative_3_0_0` ... (21 out of 24)\n",
      "Vocab count: 1190\n",
      "Token count: 52234\n",
      "unique 2gram count: 13245\n",
      "2gram count: 52329.0\n",
      "Laplace smoothing: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1190/1190 [00:42<00:00, 27.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Processing 304 documents for prompt, `tii/uniforms_argumentative_3_0_0` ... (22 out of 24)\n",
      "Vocab count: 1589\n",
      "Token count: 93951\n",
      "unique 2gram count: 24498\n",
      "2gram count: 94255.0\n",
      "Laplace smoothing: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1589/1589 [01:05<00:00, 24.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Processing 52 documents for prompt, `tii/womens_suffrage_and_equal_rights_analysis_1_0_0` ... (23 out of 24)\n",
      "Vocab count: 1023\n",
      "Token count: 28477\n",
      "unique 2gram count: 10389\n",
      "2gram count: 28529.0\n",
      "Laplace smoothing: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1023/1023 [00:32<00:00, 31.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Processing 36 documents for prompt, `tii/youve_got_a_friend_narrative_3_0_0` ... (24 out of 24)\n",
      "Vocab count: 547\n",
      "Token count: 10408\n",
      "unique 2gram count: 5267\n",
      "2gram count: 10444.0\n",
      "Laplace smoothing: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 547/547 [00:07<00:00, 73.60it/s]\n"
     ]
    }
   ],
   "source": [
    "all_clusters = []\n",
    "all_codes = []\n",
    "\n",
    "for i, k in enumerate(sorted(all_texts)):\n",
    "    print('*' * 50)\n",
    "    print(f'Processing {len(all_texts[k])} documents for prompt, `{k}` ... ({i+1} out of {len(all_texts)})')\n",
    "    processed_tokens = [[str(t).strip().lower() for t in tokenizer(text) if str(t).strip() != ''] for text in sorted(all_texts[k])]\n",
    "    #  and str(t).strip().lower() not in nlp.Defaults.stop_words\n",
    "    corpus = BigramCorpus(processed_tokens, alpha=0.25, min_count=3)\n",
    "    corpus.print_stats()\n",
    "    \n",
    "    clustering = BrownClustering(corpus, m=500)\n",
    "    clusters = clustering.train()\n",
    "    \n",
    "    all_clusters.append(clusters)\n",
    "    all_codes.append(clustering.codes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc76eb6c-e811-4d35-9361-296ab6fab9e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('brown_clusters.by_prompt.with_stopwords.pkl', 'wb') as f:\n",
    "    pickle.dump((all_clusters, all_codes), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59c1b90a-c19f-4199-9d7d-692527ca980a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_GROUPS = 40\n",
    "\n",
    "all_groups = []\n",
    "\n",
    "for clusters, codes in zip(all_clusters, all_codes):\n",
    "    for n in range(10, 1, -1):\n",
    "        groups = defaultdict(list)\n",
    "        for token, code in codes.items():\n",
    "            groups[code[:n]].append(token)\n",
    "            \n",
    "        if len(groups) <= MAX_GROUPS:\n",
    "            all_groups.append([set(group) for group in groups.values()])\n",
    "            break\n",
    "    #all_groups.append(list(groups.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8083dc44-f54e-4342-9cea-6c6f689cf5c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[249, 6, 72, 24, 29, 42, 78, 82, 32, 107, 235, 39, 76, 21, 26, 21, 25, 31, 29, 11, 4, 8, 6, 4, 2, 2, 2, 1, 1, 1, 2, 1]\n",
      "[80, 18, 71, 118, 254, 16, 36, 24, 386, 21, 16, 27, 21, 6, 11, 15, 9, 5, 4, 6, 6, 5, 1, 1, 3, 1, 1, 1, 1, 1, 1]\n",
      "[134, 459, 58, 49, 71, 33, 10, 11, 16, 12, 24, 13, 23, 9, 2, 3, 3, 2, 5, 1, 2, 1, 1, 1, 1, 1]\n",
      "[123, 16, 62, 89, 96, 141, 625, 54, 41, 146, 28, 50, 22, 13, 25, 15, 6, 8, 12, 3, 5, 5, 4, 3, 2, 2, 1, 1, 1, 3, 1, 2]\n",
      "[20, 72, 47, 34, 120, 231, 18, 51, 321, 50, 71, 24, 87, 144, 47, 27, 6, 15, 5, 6, 2, 4, 1, 1, 1]\n",
      "[18, 58, 63, 34, 116, 41, 42, 31, 11, 17, 22, 30, 19, 12, 9, 11, 5, 21, 4, 3, 3, 13, 7, 4, 3, 5, 5, 3, 1, 1, 4, 1]\n",
      "[73, 108, 549, 35, 69, 48, 24, 35, 11, 25, 11, 19, 9, 6, 13, 3, 20, 4, 4, 4, 1, 1, 1, 1, 1]\n",
      "[84, 22, 20, 27, 13, 6, 13, 7, 6, 18, 2, 10, 2, 3, 16, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[11, 17, 41, 125, 50, 362, 49, 56, 19, 38, 17, 18, 67, 21, 41, 4, 13, 5, 3, 3, 5, 4, 3, 2, 1, 1, 1, 1, 1, 1]\n",
      "[197, 37, 168, 74, 97, 306, 15, 30, 41, 28, 8, 9, 11, 53, 5, 8, 9, 11, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1]\n",
      "[86, 237, 26, 858, 154, 115, 119, 448, 32, 59, 7, 14, 45, 78, 22, 14, 4, 6, 11, 4, 7, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[32, 443, 156, 100, 15, 63, 21, 48, 32, 16, 7, 11, 28, 10, 14, 6, 6, 44, 3, 17, 8, 2, 7, 5, 4, 3, 2, 1, 2, 1, 1, 1]\n",
      "[141, 37, 17, 81, 41, 341, 39, 93, 51, 10, 28, 40, 15, 25, 17, 10, 21, 11, 12, 8, 19, 9, 7, 1, 1, 2, 1, 1]\n",
      "[31, 211, 11, 51, 170, 45, 60, 46, 23, 26, 34, 6, 25, 13, 24, 21, 10, 9, 25, 21, 5, 11, 3, 3, 3, 1, 1, 1, 1, 1, 1]\n",
      "[33, 113, 15, 18, 49, 121, 128, 107, 132, 283, 52, 16, 48, 12, 5, 22, 10, 16, 17, 11, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1]\n",
      "[441, 46, 47, 150, 57, 120, 337, 12, 570, 13, 28, 34, 25, 15, 15, 19, 4, 3, 9, 7, 2, 1, 1, 1, 2, 1, 2, 1, 1]\n",
      "[165, 220, 28, 37, 40, 14, 28, 8, 9, 10, 15, 4, 19, 9, 17, 4, 13, 4, 2, 4, 5, 4, 2, 2, 1, 1]\n",
      "[29, 22, 36, 37, 206, 84, 19, 36, 30, 8, 27, 8, 16, 2, 3, 4, 16, 1, 1, 3, 1, 1, 1, 1, 1, 1]\n",
      "[101, 54, 195, 43, 68, 583, 29, 63, 72, 11, 23, 12, 5, 3, 1, 1, 9, 5, 10, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[14, 127, 198, 142, 105, 30, 6, 71, 466, 28, 10, 6, 10, 47, 13, 18, 14, 4, 7, 27, 8, 7, 7, 5, 2, 2, 2, 4, 5, 1, 1, 1]\n",
      "[84, 62, 126, 71, 125, 17, 176, 103, 190, 18, 37, 22, 54, 12, 7, 7, 17, 12, 3, 34, 4, 5, 2, 1, 1]\n",
      "[44, 108, 99, 18, 95, 459, 441, 8, 95, 30, 25, 48, 3, 24, 9, 7, 8, 4, 12, 26, 5, 3, 4, 2, 2, 3, 1, 1, 2, 1, 1, 1]\n",
      "[68, 21, 255, 110, 48, 330, 21, 19, 17, 6, 9, 20, 23, 12, 8, 4, 6, 5, 14, 2, 4, 3, 3, 2, 3, 5, 1, 1, 1, 1, 1]\n",
      "[67, 198, 31, 119, 31, 32, 13, 6, 7, 4, 12, 4, 2, 2, 3, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "for groups in all_groups:\n",
    "    print ([len(group) for group in groups])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "670fef5c-7ed3-4712-84ed-01a572ef9025",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List, Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd99fea5-8ca1-47c6-87ee-205838e67824",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def common_sets(lists_of_sets: List[List[Set[str]]], threshold: float = 0.5) -> List[Set[str]]:\n",
    "    \"\"\"\n",
    "    Returns a list of sets of words that are the common sets between all of the given lists of sets.\n",
    "    \n",
    "    :param lists_of_sets: A list of lists of sets of words.\n",
    "    :param threshold: The threshold for the Jaccard similarity coefficient to consider two sets as common.\n",
    "    :return: A list of sets of words that are the common sets between all of the given lists of sets.\n",
    "    \"\"\"\n",
    "    # Compute the Jaccard similarity coefficient between each pair of sets.\n",
    "    similarities = []\n",
    "    for i, sets_i in enumerate(lists_of_sets):\n",
    "        for j, sets_j in enumerate(lists_of_sets[i+1:], start=i+1):\n",
    "            for set_i in sets_i:\n",
    "                for set_j in sets_j:\n",
    "                    similarity = len(set_i.intersection(set_j)) / len(set_i.union(set_j))\n",
    "                    if similarity >= threshold:\n",
    "                        similarities.append((i, j, set_i, set_j))\n",
    "                        \n",
    "    # Group the sets that have a Jaccard similarity coefficient above the threshold.\n",
    "    groups = {}\n",
    "    for i, j, set_i, set_j in similarities:\n",
    "        if frozenset(set_i) not in groups:\n",
    "            groups[frozenset(set_i)] = {i, j}\n",
    "        else:\n",
    "            groups[frozenset(set_i)].add(i)\n",
    "            groups[frozenset(set_i)].add(j)\n",
    "        if frozenset(set_j) not in groups:\n",
    "            groups[frozenset(set_j)] = {i, j}\n",
    "        else:\n",
    "            groups[frozenset(set_j)].add(i)\n",
    "            groups[frozenset(set_j)].add(j)\n",
    "            \n",
    "    # Return the sets that belong to all the groups.\n",
    "    if len(groups) == 0:\n",
    "        return []\n",
    "    common_sets = set()\n",
    "    for set_i, group_i in groups.items():\n",
    "        if len(group_i) == len(lists_of_sets):\n",
    "            common_sets.add(frozenset(set_i))\n",
    "    return list(common_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23116db4-8e1d-485d-93c8-0da84053e228",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_out = common_sets(all_groups, .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "770d24d3-2b0a-4a70-b23f-a8bd30bde5b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c69b31a-a2db-45f9-9552-b0e69dc3207b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "does, did, is, was, actually, should, have, could, had, also, can, 's, were, still, would, are, will\n",
      "\n",
      "that, from, to, during, over, but, on, \", as, between, which, against, with, because, by\n",
      "\n",
      "into, for, from, on, at, of, with, in\n",
      "\n",
      "about, for, from, on, of, as, with, in\n",
      "\n",
      ",, .\n",
      "\n",
      "but, on, between, ', it, when, out, by, how, with, each, because, in, if, what, that, moki, and, he, of, as, one, which, they, about, from, for, to, we, \", there, both, this, where\n",
      "\n",
      "there, this, it, owning, he\n",
      "\n",
      "then, after, what, 2, all, many, no, an, though, one, which, when, although, shirely, while, these, since, why, how, most, both, two, if\n",
      "\n",
      "everybody, all, many, (, eliminating, like, ', who, some, by, just, into, why, made, how, also, nobody, making, at, assigned, with, :, than, every, -, then, page, having, even, given, though, which, although, or, about, these, from, since, for, only, we, ?, lois, two, without, being, where\n",
      "\n",
      "a, the\n",
      "\n",
      "what, that, how, but, because, who, when, if\n",
      "\n",
      "that, about, for, from, how, on, at, like, with\n",
      "\n",
      "but, \", that, ., ,, because, and\n",
      "\n",
      "\", of, on, in, and\n",
      "\n",
      "then, what, after, '', that, so, and, but, as, like, when, about, why, how, because, if, where\n",
      "\n",
      "then, what, that, so, and, but, as, when, if\n",
      "\n",
      ".\n",
      "\n",
      "everything, there, everyone, this, it, jonas, he\n",
      "\n",
      "do, have, was, were, are, is\n",
      "\n",
      "or, what, that, so, and, how, but, because, who, when, if\n",
      "\n",
      "there, you, this, they, it, we\n",
      "\n",
      "then, after, that, so, and, but, \", as, because, when, if\n",
      "\n",
      "or, from, for, and, through, on, at, \", as, with, in, by\n",
      "\n",
      "it, what, that, so, and, is, but, at, as, because, this, when, if\n",
      "\n",
      ",, and, ., is\n",
      "\n",
      "do, have, did, could, had, were, would, are\n",
      "\n",
      "do, and, n't, but, on, of, or, have, for, be, to, not, use, with, in, are\n",
      "\n",
      ",, that, .\n",
      "\n",
      "throughout, on, of, like, over, by, about, from, for, to, shows, made, through, at, with, in\n",
      "\n",
      "on, at, of, for, with, to, in\n",
      "\n",
      "do, did, said, could, can, were, would, are, will\n",
      "\n",
      "about, that, for, been, not, given, n't, more, on, as, with, because, than, by\n",
      "\n",
      "what, that, so, but, as, because, when, if\n",
      "\n",
      "mark, after, marc, so, but, on, like, killed, who, when, it, by, loved, why, how, at, with, because, in, than, if, then, what, julius, and, of, as, one, which, they, while, about, for, to, ceasar, \", there, i, both, this, you\n",
      "\n",
      "a, the, his, their\n",
      "\n",
      "after, that, taking, so, and, but, \", as, because, when, if\n",
      "\n",
      "then, after, what, that, so, and, but, \", as, because, when, if\n",
      "\n",
      "then, what, that, so, how, but, as, like, because, when, if\n",
      "\n",
      "do, did, will, n't, is, get, was, just, have, be, wait, could, not, can, 's, were, would, are, go\n",
      "\n",
      "then, what, that, having, so, and, but, on, of, as, who, because, when, by, or, wearing, about, from, for, why, how, \", at, with, in, if\n",
      "\n",
      "\", of, to, and, in\n",
      "\n",
      "do, will, want, get, need, should, have, be, to, may, could, start, can, 's, would, are, go\n",
      "\n",
      "then, after, what, so, on, though, like, as, when, by, while, before, about, into, from, for, why, how, at, with, if\n",
      "\n",
      "after, what, that, all, even, sometimes, on, as, like, because, when, by, from, for, how, through, at, with, in, if\n",
      "\n",
      "what, as, to, because, when, and\n",
      "\n",
      "a, the, their, your\n",
      "\n",
      "then, after, so, but, \", as, because, when, if\n",
      "\n",
      "what, that, bruce, (, how, but, as, i, which, because, when\n",
      "\n",
      "about, from, for, to, on, at, of, like, with, in\n",
      "\n",
      "do, try, want, get, like, was, 'm, just, should, have, be, might, may, could, pop, am, think, know, also, seem, appeal, buy, can, believe, use, look, really, would, see, go, will\n",
      "\n",
      "or, \", that, in, and\n",
      "\n",
      "then, what, so, but, on, as, like, away, creating, when, by, about, into, from, for, such, how, at, with, because, than, if, where\n",
      "\n",
      "what, that, ,, words, and, is, but, of, communication, because, it, the, way, \", with, in\n",
      "\n",
      "on, of, for, with, in\n",
      "\n",
      "do, need, did, have, had, want, has, were, are\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for s in test_out:\n",
    "    print (', '.join(s))\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3759ce0c-1005-4cf9-9307-fae6c4ec09f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'intersection'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_out \u001b[38;5;241m=\u001b[39m \u001b[43mcommon_sets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 15\u001b[0m, in \u001b[0;36mcommon_sets\u001b[0;34m(lists_of_sets, threshold)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m set_i \u001b[38;5;129;01min\u001b[39;00m sets_i:\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m set_j \u001b[38;5;129;01min\u001b[39;00m sets_j:\n\u001b[0;32m---> 15\u001b[0m         similarity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mset_i\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintersection\u001b[49m(set_j)) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(set_i\u001b[38;5;241m.\u001b[39munion(set_j))\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m similarity \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m threshold:\n\u001b[1;32m     17\u001b[0m             similarities\u001b[38;5;241m.\u001b[39mappend((i, j, set_i, set_j))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'intersection'"
     ]
    }
   ],
   "source": [
    "test_out = common_sets(test_out, .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2115447c-4df8-4ea0-a1d5-fdee3ff0d178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "816401a4-8af2-4294-92d8-78b47615c9a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_columns(words_list, start_idx=0):\n",
    "    \"\"\"\n",
    "    Prints a list of lists of words in row format, with a header row and separator row.\n",
    "    \n",
    "    :param words_list: A list of lists of words.\n",
    "    \"\"\"\n",
    "    # Compute the maximum length of each row.\n",
    "    num_cols = len(words_list)\n",
    "    col_lengths = [max(len(word) for word in row) for row in words_list]\n",
    "    col_size = [len(w) for w in words_list]\n",
    "    \n",
    "    # Compute the maximum length of the header and the longest word in the column.\n",
    "    header_lengths = [len(f'Feature {j}') for j in range(num_cols)]\n",
    "    max_lengths = [max(header_lengths[j], col_lengths[j]) for j in range(num_cols)]\n",
    "    \n",
    "    # Print the header row with column labels.\n",
    "    for j in range(num_cols):\n",
    "        header = f'Group {j+start_idx}'\n",
    "        padding = ' ' * (max_lengths[j] - len(header))\n",
    "        print(header + padding, end='  ')\n",
    "    print()\n",
    "    \n",
    "    # Print the separator row with dashes.\n",
    "    for j in range(num_cols):\n",
    "        separator = '-' * max_lengths[j]\n",
    "        print(separator, end='  ')\n",
    "    print()\n",
    "    \n",
    "    # Print the words in row format.\n",
    "    for i in range(max(col_size)):\n",
    "        for j in range(num_cols):\n",
    "            word = words_list[j][i] if i < len(words_list[j]) else ''\n",
    "            padding = ' ' * (max_lengths[j] - len(word))\n",
    "            print(word + padding, end='  ')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "527fb1a0-0bc0-4451-8253-7ba223805149",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 1        Group 2      Group 3     Group 4    Group 5    Group 6      Group 7    Group 8    Group 9     Group 10   \n",
      "-------------  -----------  ----------  ---------  ---------  -----------  ---------  ---------  ----------  ---------  \n",
      "advantage      ;            attention   asked      believe    1            know       bad        carolyn     bad        \n",
      "answer         able         based       came       different  actually     need       care       different   bullying   \n",
      "best           actually     believe     day        example    author       people     come       fell        children   \n",
      "communication  age          clothing    found      good       happened     play       cry        important   clothing   \n",
      "conclusion     appeal       come        going      having     life         tell       dad        karcyn      cost       \n",
      "cons           better       game        know       identity   note         want       divice     lesson      decrease   \n",
      "convenient     big          help        looking    important  quote                   ended      life        expensive  \n",
      "day            brand        interested  ran        know       real                    hallway    little      good       \n",
      "easier         business     looking     started    life       represented             having     needed      help       \n",
      "easy           businesses   makes       think      like       represents              little     nt          idea       \n",
      "example        capture      money       time       mean       sharing                 math       okay        people     \n",
      "faster         comes        phone                  thing      showed                  night      pressurize  prevent    \n",
      "going          completely   pop                    think      shown                   picked     quote       schools    \n",
      "great          conclusion   receive                way        shows                   playing    ran         stop       \n",
      "hand           consider     seen                              story                   s          real        student    \n",
      "instead        create       send                              told                    saying     riding      thing      \n",
      "know           depends      shows                             way                     sister     sister      way        \n",
      "pros           describe     try                                                       sun        stop                   \n",
      "quick          directed     trying                                                    wanted     thing                  \n",
      "reasons        enjoy        want                                                                 tire                   \n",
      "thing          favorite     ways                                                                 trying                 \n",
      "things         feel         website                                                              work                   \n",
      "think          find                                                                              yes                    \n",
      "time           follow                                                                                                   \n",
      "               food                                                                                                     \n",
      "               friends                                                                                                  \n",
      "               fun                                                                                                      \n",
      "               getting                                                                                                  \n",
      "               girl                                                                                                     \n",
      "               girls                                                                                                    \n",
      "               going                                                                                                    \n",
      "               good                                                                                                     \n",
      "               google                                                                                                   \n",
      "               high                                                                                                     \n",
      "               history                                                                                                  \n",
      "               important                                                                                                \n",
      "               interest                                                                                                 \n",
      "               interests                                                                                                \n",
      "               likely                                                                                                   \n",
      "               love                                                                                                     \n",
      "               main                                                                                                     \n",
      "               majority                                                                                                 \n",
      "               makeup                                                                                                   \n",
      "               million                                                                                                  \n",
      "               music                                                                                                    \n",
      "               need                                                                                                     \n",
      "               nt                                                                                                       \n",
      "               offline                                                                                                  \n",
      "               pay                                                                                                      \n",
      "               personality                                                                                              \n",
      "               pretty                                                                                                   \n",
      "               profile                                                                                                  \n",
      "               related                                                                                                  \n",
      "               right                                                                                                    \n",
      "               school                                                                                                   \n",
      "               search                                                                                                   \n",
      "               searches                                                                                                 \n",
      "               seeing                                                                                                   \n",
      "               targeting                                                                                                \n",
      "               teens                                                                                                    \n",
      "               tend                                                                                                     \n",
      "               thing                                                                                                    \n",
      "               times                                                                                                    \n",
      "               type                                                                                                     \n",
      "               usually                                                                                                  \n",
      "               watch                                                                                                    \n",
      "               youtube                                                                                                  \n",
      "\n",
      "Group 11   Group 12   Group 13   Group 14   Group 15    Group 16   Group 17    Group 18   Group 19      Group 20   \n",
      "---------  ---------  ---------  ---------  ----------  ---------  ----------  ---------  ------------  ---------  \n",
      "choice     able       find       know       bad         able       better      different  ambition      bad        \n",
      "choices    career     like       life       conspiring  asked      different   know       audience      equality   \n",
      "different  children   look       people     countries   bad        persuasive  like       bad           good       \n",
      "elders     different  people     thing      country     best       purpose     look       cassius       rules      \n",
      "feel       focus      saw        things     fair        better     said        people     ceasar        sameness   \n",
      "feelings   future                way        happen      come       shows       things     conspirators  thing      \n",
      "having     good                             help        comes      similar     think      die           things     \n",
      "know       grades                           humble      decided    tone                   end                      \n",
      "life       having                           life        family     trying                 example                  \n",
      "like       know                             like        friend     way                    feel                     \n",
      "live       life                             little      games                             friend                   \n",
      "lives      look                             nation      great                             friends                  \n",
      "nt         mind                             need        help                              hath                     \n",
      "perfect    plan                             poor        knew                              instance                 \n",
      "think      ready                            poorest     mother                            leader                   \n",
      "utopia     things                           small       parents                           like                     \n",
      "want       think                            things      phone                             person                   \n",
      "way        want                             time        started                           poor                     \n",
      "world      work                             turn        story                             power                    \n",
      "                                            world       takes                             reason                   \n",
      "                                                        taking                            right                    \n",
      "                                                        tell                              romans                   \n",
      "                                                        thought                           thing                    \n",
      "                                                        want                              think                    \n",
      "                                                        wanted                            times                    \n",
      "                                                                                          want                     \n",
      "                                                                                          wanted                   \n",
      "                                                                                          wrong                    \n",
      "\n",
      "Group 21     Group 22   \n",
      "-----------  ---------  \n",
      "argue        begin      \n",
      "believe      believe    \n",
      "benefits     better     \n",
      "bullied      classes    \n",
      "communicate  colleges   \n",
      "day          earlier    \n",
      "going        feel       \n",
      "having       help       \n",
      "information  important  \n",
      "inspired     kids       \n",
      "know         later      \n",
      "life         learn      \n",
      "lives        like       \n",
      "look         need       \n",
      "looking      parents    \n",
      "online       people     \n",
      "posting      process    \n",
      "time         schools    \n",
      "type         started    \n",
      "work         starting   \n",
      "             student    \n",
      "             time       \n",
      "             years      \n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_columns = 10\n",
    "for i in range(0, len(test_out), n_columns):\n",
    "    if i+n_columns >= len(test_out):\n",
    "        print_columns([sorted(t) for t in test_out[i:]], i+1)\n",
    "    else:\n",
    "        print_columns([sorted(t) for t in test_out[i:i+n_columns]], i+1)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0f3a5d-c2a1-4c2b-9b07-577ebcb4d9cb",
   "metadata": {},
   "source": [
    "### Feature 1:\n",
    "```best, things, easier, advantage, instead, quick, going, reasons, great, think, pros, answer, know, hand, time, thing, easy, example, day, convenient, communication, faster, cons, conclusion```\n",
    "\n",
    "Efficiency or convinience\n",
    "\n",
    "### Feature 2:\n",
    "```school, business, ;, pretty, enjoy, favorite, getting, searches, capture, girl, history, thing, tend, teens, food, age, friends, appeal, conclusion, brand, interest, high, better, million, love, likely, right, depends, search, follow, describe, usually, businesses, pay, actually, interests, comes, consider, good, google, majority, offline, important, directed, need, completely, youtube, girls, times, targeting, find, going, makeup, music, fun, watch, seeing, profile, able, related, personality, nt, main, type, big, create, feel```\n",
    "\n",
    "Informal teen interests (may be a prompt)\n",
    "\n",
    "### Feature 3:\n",
    "```ways, makes, come, want, phone, receive, game, website, based, send, money, seen, interested, try, help, pop, trying, shows, looking, clothing, attention, believe```\n",
    "\n",
    "Teen values (may be a prompt)\n",
    "\n",
    "### Feature 4:\n",
    "```came, found, time, going, ran, started, think, day, looking, know, asked```\n",
    "\n",
    "Basic actions/activities\n",
    "\n",
    "### Feature 5:\n",
    "```way, like, important, identity, thing, different, think, example, mean, having, believe, good, know, life```\n",
    "\n",
    "Opinion declarations\n",
    "\n",
    "### Feature 6:\n",
    "```story, way, represents, sharing, showed, life, happened, represented, shown, told, 1, shows, real, quote, note, author, actually```\n",
    "\n",
    "Storytelling, quoting (analysis genre reflections)\n",
    "\n",
    "### Feature 7:\n",
    "```play, need, want, tell, people, know```\n",
    "\n",
    "Simple communicative actions\n",
    "\n",
    "### Feature 8:\n",
    "```sister, come, picked, cry, having, playing, night, math, bad, divice, dad, little, wanted, saying, ended, care, sun, hallway, s```\n",
    "\n",
    "Informal (including misspellings) tangent (presonal narrative)\n",
    "\n",
    "### Feature 9:\n",
    "```sister, carolyn, different, stop, lesson, work, riding, fell, life, okay, important, nt, ran, thing, little, trying, yes, real, tire, quote, needed, karcyn, pressurize```\n",
    "\n",
    "Personal narrative\n",
    "\n",
    "### Feature 10:\n",
    "```way, idea, prevent, decrease, stop, people, good, student, bad, help, children, thing, expensive, cost, schools, clothing, bullying```\n",
    "\n",
    "Cost anlaysis (in schools) (prompt)\n",
    "\n",
    "### Feature 11:\n",
    "```elders, way, want, feel, choices, different, think, having, know, life, feelings, like, world, choice, nt, utopia, lives, perfect, live```\n",
    "\n",
    "Feelings/ideals\n",
    "\n",
    "### Feature 12:\n",
    "```things, want, grades, different, think, having, focus, good, work, able, know, life, career, plan, future, children, look, mind, ready```\n",
    "\n",
    "Life goals/priorities\n",
    "\n",
    "### Feature 13:\n",
    "```like, saw, find, look, people```\n",
    "\n",
    "Simple observations\n",
    "\n",
    "### Feature 14:\n",
    "```things, way, life, thing, people, know```\n",
    "\n",
    "Simple general concepts\n",
    "\n",
    "### Feature 15:\n",
    "```things, happen, turn, countries, country, life, fair, conspiring, bad, nation, like, time, world, help, poor, little, need, humble, small, poorest```\n",
    "\n",
    "Societal fairness (may be interesting if that gets groups with demographics)\n",
    "\n",
    "### Feature 16:\n",
    "```best, decided, story, mother, come, want, taking, phone, friend, started, great, takes, comes, knew, better, able, asked, bad, family, help, tell, games, wanted, parents, thought```\n",
    "\n",
    "Parental intent/decisiosn (personal narrative)\n",
    "\n",
    "### Feature 17:\n",
    "```purpose, said, way, different, tone, persuasive, trying, shows, better, similar```\n",
    "\n",
    "Meta-persuasive terms\n",
    "\n",
    "### Feature 18:\n",
    "```things, like, look, know, different, people, think```\n",
    "\n",
    "General population comparison\n",
    "\n",
    "### Feature 19:\n",
    "```times, want, die, conspirators, friend, leader, wrong, power, think, reason, person, audience, ceasar, ambition, cassius, end, bad, right, like, thing, poor, example, wanted, romans, instance, hath, friends, feel```\n",
    "\n",
    "Conflict, historical (prompt)\n",
    "\n",
    "### Feature 20:\n",
    "```bad, things, rules, good, sameness, thing, equality```\n",
    "\n",
    "Sameness judgement\n",
    "\n",
    "### Feature 21:\n",
    "```going, online, posting, inspired, having, information, work, know, life, bullied, benefits, time, argue, communicate, looking, day, type, believe, look, lives```\n",
    "\n",
    "Online interactions (prompts)\n",
    "\n",
    "### Feature 22:\n",
    "```years, begin, started, people, classes, better, student, later, kids, like, learn, important, time, colleges, help, earlier, starting, need, schools, believe, parents, process, feel```\n",
    "\n",
    "School concepts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "59f4f7f3-e8dc-4622-bf8f-637478a8a4d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "word_groups = {\n",
    "    'Efficiency or convinience' : test_out[0],\n",
    "    'Informal teen interests' : test_out[1],\n",
    "    'Teen values' : test_out[2],\n",
    "    'Basic actions/activities' : test_out[3],\n",
    "    'Opinion declarations' : test_out[4],\n",
    "    'Storytelling, quoting' : test_out[5],\n",
    "    'Simple communicative actions' : test_out[6],\n",
    "    'Informal tangents' : test_out[7],\n",
    "    'UNKNOWN GROUP' : test_out[8],\n",
    "    'Cost anlaysis (in schools)' : test_out[9],\n",
    "    'Feelings/ideals' : test_out[10],\n",
    "    'Life goals/priorities' : test_out[11],\n",
    "    'Simple observations' : test_out[12],\n",
    "    'Simple general concepts' : test_out[13],\n",
    "    'Societal fairness' : test_out[14],\n",
    "    'Parental intent/decisiosn' : test_out[15],\n",
    "    'Meta-persuasive terms' : test_out[16],\n",
    "    'General population comparison' : test_out[17],\n",
    "    'Conflict, historical' : test_out[18],\n",
    "    'Sameness judgement' : test_out[19],\n",
    "    'Online interactions' : test_out[20],\n",
    "    'School concepts' : test_out[21],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "8eacd4c1-e769-4286-a463-51edc4dead4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('named_common_clusters.pkl', 'wb') as f:\n",
    "    pickle.dump(word_groups, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc4bfb0-b28c-414c-b991-1b3ecb468f4d",
   "metadata": {},
   "source": [
    "# OLD - DO NOT USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f81664f1-23e3-480f-a8c9-f08599d2b439",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = sorted(all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1fe4058-9c4f-446f-aa6f-ee9a1ef6c130",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_prompts = sorted(all_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76d64a63-45aa-4914-86fc-91e7d675b3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_tokens = [[str(t).strip().lower() for t in tokenizer(text) if str(t).strip() != '' and str(t).strip().lower() not in nlp.Defaults.stop_words] for text in all_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08e8d9f5-4057-4b03-a7db-c9d5fe30426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = BigramCorpus(processed_tokens, alpha=0.25, min_count=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3300bc74-b856-4b95-8749-03f0fe030bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab count: 9270\n",
      "Token count: 367485\n",
      "unique 2gram count: 234776\n",
      "2gram count: 369762.0\n",
      "Laplace smoothing: 0.25\n"
     ]
    }
   ],
   "source": [
    "corpus.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2c35e5b1-c3b2-49a0-86c9-b36e65f90295",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = BrownClustering(corpus, m=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d182936b-16f7-4faf-800d-50a21060a213",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 9272/9272 [53:17<00:00,  2.90it/s]\n"
     ]
    }
   ],
   "source": [
    "clusters = clustering.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2e425ddf-0ce8-40f6-b0e5-f21dd95a1908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d2a70248-b5ee-4b36-bef5-cf805242a6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('brown_clusters.all.json', 'r') as f:\n",
    "    c = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8e1307a8-2e21-4a68-9fd1-2734a1cce910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 9272)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c['clusters']), len(c['codes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e78cf96d-c8fa-4203-8e96-56cf9525ea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "BITS = 5\n",
    "\n",
    "groups = defaultdict(lambda: [])\n",
    "for token, code in c['codes'].items():\n",
    "    groups[code[:BITS]].append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "afcda2d8-8305-4f9e-bad1-f5ed085dfd29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "20bcc2c9-3e99-466e-8ec4-fda572941f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  446 flight, mr., air, sleeping, city, road, ice, pulled, homework, quiet\n",
      "\n",
      "   77 melons, melon, drive, drove, 7, 9, culture, fully, plants, crops\n",
      "\n",
      "  266 products, product, facebook, instagram, crime, leads, consider, considered, relationships, filled\n",
      "\n",
      "  536 storm, statue, placed, greatly, shape, columbus, described, wind, hurricanes, street\n",
      "\n",
      "  281 monuments, general, species, animals, believes, believed, aristotle, sartre, differences, sort\n",
      "\n",
      "   25 persuade, convince, kill, killing, cried, bury, roman, slaves, julius, death\n",
      "\n",
      "   44 appeals, devices, rhetorical, literary, sameness, individuals, ads, advertisements, logos, ethos\n",
      "\n",
      "  891 met, near, success, successful, earthquake, tragedy, britian, bengal, facts, statement\n",
      "\n",
      "  263 joke, jokes, prepare, preparing, lots, rich, works, worked, faster, cousin\n",
      "\n",
      " 6013 territories, ball, conflicts, spot, leader, friendly, position, sight, crown, fruit\n",
      "\n",
      "   36 higher, lower, math, science, improve, increase, lowry, released, utopia, provide\n",
      "\n",
      "   44 prussia, austria, wars, battles, colonization, win, king, attack, allies, colonists\n",
      "\n",
      "   60 shirt, outfit, required, uncomfortable, individuality, creativity, expression, esteem, cloths, colors\n",
      "\n",
      "   41 spoke, persuasive, conspirators, emotional, mainly, tries, appeal, device, funeral, alive\n",
      "\n",
      "   84 lines, writes, harmony, peacefully, tribe, indian, response, builds, para, paragraph\n",
      "\n",
      "    1 webpage\n",
      "\n",
      "    1 winnie\n",
      "\n",
      "    1 ©\n",
      "\n",
      "    1 °\n",
      "\n",
      "   19 expensive, cost, stop, prevent, uniform, clothing, children, student, nt, wo\n",
      "\n",
      "   66 waiting, waited, takes, taken, wait, looked, felt, talking, talk, told\n",
      "\n",
      "    9 hear, sing, langston, walt, whitman, hughes, singing, poem, america\n",
      "\n",
      "   25 society, community, says, saying, idea, point, reason, conclusion, brutus, antony\n",
      "\n",
      "    4 students, kids, wear, school\n",
      "\n",
      "   28 great, best, important, makes, able, need, feel, look, lot, save\n",
      "\n",
      "    3 water, robes, house\n",
      "\n",
      "    3 man, black, wasp\n",
      "\n",
      "    2 social, media\n",
      "\n",
      "    1 uniforms\n",
      "\n",
      "    1 people\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for group in groups:\n",
    "    print(str(len(groups[group])).rjust(5), ', '.join(groups[group][:10]))  # , \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7185095e-8112-4e46-ac5d-0b4d452848a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.  flight, mr., air, sleeping, city, road, ice, pulled, homework, quiet, dear, suddenly, immediately, loud, noise, sent, watched, scared, excited, fell, stopped, practice, clean, floor, yelled, colleges, hot, replied, oh, test, dog, forward, washington, grabbed, park, cars, bike, stood, laughs, mall, ok, quickly, hair, worried, etc, sitting, mans, movie, news, asleep, sudden, tree, running, acting, talked, nervous, town, officer, opened, standing, stayed, winter, jumped, partner, answered, confused, followed, guys, lunch, cat, officers, slowly, rope, missing, riding, 90, awake, fire, perfectly, warm, chair, crying, sit, lay, snow, cry, broken, sorry, clock, dressed, gift, office, stomach, busy, hurricane, neighbor, scream, son, stairs, hotel\n",
      "\n",
      "2.  melons, melon, drive, drove, 7, 9, culture, fully, plants, crops, seven, 12, opposite, pueblo, safety, reach, watermelon, grew, grown, 30, 20, 8, ceasar, b, 15, plant, planted, 11, forbidden, notes, welcomed, 25, bloody, diane, hundreds, thirty, hidden, 1680, e, lasted, 16, gardens, c, missionaries, planting, tear, 24, brutal, kawayvatnga, , #, seed, driven, f, d, healing, explorers, outlawed, 45, resent, priests, g, 10, couple, 6, dreams, growing, finding, garden, truth, 4, 5, blue, dark, multiple, secret, —\n",
      "\n",
      "3.  products, product, facebook, instagram, crime, leads, consider, considered, relationships, filled, music, sports, possibly, %, pictures, quick, study, research, internet, ad, constantly, forever, mood, moments, thank, annoying, picked, bully, losing, loss, achieve, complete, energy, studies, classes, personally, environment, keeps, education, level, definitely, obviously, stuck, prepared, target, opportunity, straight, $, planning, career, interests, likes, meant, system, interesting, weird, football, guess, expressing, hate, phones, basketball, blood, beating, lets, letting, companies, advertisers, earlier, held, extra, spent, shirts, fit, task, ultimately, determined, rid, skin, played, finished, receive, favorite, regular, [, ], activities, buying, force, fix, post, hearing, basically, pride, listen, trust, aware, pain, happier, business\n",
      "\n",
      "4.  storm, statue, placed, greatly, shape, columbus, described, wind, hurricanes, street, non, shall, mourn, nearly, admit, rain, steps, apple, constant, january, searching, surely, ignored, martin, bill, green, harsh, robert, slightly, chosen, gabe, lie, soul, art, consequences, recognized, storms, setting, designed, doctors, instantly, pieces, turning, extreme, faith, maine, trash, 13, arm, original, sadness, --, observed, trees, babies, bus, deed, numbers, 100, blame, brown, dealing, massive, hunting, previous, surface, 1982, bravery, challenge, dust, rose, spring, wanna, argued, decides, diana, disappointed, lies, offended, skutnik, television, texts, intricate, stepped, brook, craftsman, double, fourth, giant, luckily, master, opening, passenger, presence, recover, usher, washing, waves, lantern, pages\n",
      "\n",
      "5.  monuments, general, species, animals, believes, believed, aristotle, sartre, differences, sort, fine, courage, memorials, plato, possessions, possession, influence, effects, views, types, trip, woke, song, proud, following, present, cared, asking, building, creating, calls, till, location, size, define, detrimental, hands, race, claims, haitian, protect, ring, sign, begins, speaks, farm, barn, jean, development, curiosity, finds, represents, represent, similarities, explain, prove, dream, lesson, perspective, songs, crash, crashed, describe, explaining, factors, represented, river, survivors, disasters, disaster, reader, readers, daily, risk, goal, goals, compared, distance, sees, grows, homes, haitians, communicate, communication, super, members, summer, christmas, selflessness, adds, special, brave, fellow, hive, colored, destroyed, deserve, expresses, heroic, prejudice\n",
      "\n",
      "6.  persuade, convince, kill, killing, cried, bury, roman, slaves, julius, death, ambitious, killed, audience, romans, tone, speeches, based, similar, die, dead, loved, words, word, poems, heart\n",
      "\n",
      "7.  appeals, devices, rhetorical, literary, sameness, individuals, ads, advertisements, logos, ethos, pathos, negative, positive, impact, effect, equality, rules, book, overall, clearly, jonas, chisholm, shirley, advertising, ownership, owning, giver, rights, men, anthony, equal, united, choice, color, citizens, rome, freedom, love, personal, sense, women, identity, self, real\n",
      "\n",
      "8.  met, near, success, successful, earthquake, tragedy, britian, bengal, facts, statement, laws, despite, red, male, terrible, experienced, action, explained, taught, supposed, creates, keeping, moving, weather, wish, gained, caught, piece, importance, beauty, pass, speaking, rule, speaker, apart, letter, subject, page, siddhartha, survive, meet, search, write, causes, causing, .., confidence, received, addition, resources, fear, anger, large, considering, europe, affected, helpful, add, image, leaving, notice, season, related, connect, birthday, passage, essay, gotten, reading, mentioned, continue, wanting, points, imagine, political, actual, happening, baby, boost, bright, forces, religion, lands, constitution, europeans, specific, particular, impacted, correct, eating, scene, field, reality, furthermore, historical, reached, tears, worst, unfair, defeat\n",
      "\n",
      "9.  joke, jokes, prepare, preparing, lots, rich, works, worked, faster, cousin, adults, teens, older, younger, necessary, harder, experiences, stories, involved, somebody, walking, walk, table, india, okay, '', belongs, varied, blithe, kitchen/, memories, question, questions, boring, cool, capsule, ticket, normal, single, watch, watching, upset, angry, amazing, exactly, difficult, check, party, forget, smile, anymore, worth, walked, sat, beginning, instance, turned, late, ended, ground, starting, starts, plan, crazy, hour, minute, hit, extremely, games, video, break, follow, stress, trouble, possible, common, stand, speak, simple, easy, calm, fast, ran, wake, tired, needs, hold, bit, kitchen, especially, simply, nice, lived, named, laughed, bed, fall, sister, teacher, hope\n",
      "\n",
      "10.  territories, ball, conflicts, spot, leader, friendly, position, sight, crown, fruit, qualities, thin, enemies, latest, leaders, bigger, directly, lifestyle, trading, winning, planet, method, current, doubt, influenced, island, outcome, understood, damage, expressed, foot, ripped, content, generation, jafar, maria, pushing, surprise, teen, weight, chief, ears, exist, foreign, humanity, threat, aid, challenges, comfort, informed, local, positions, providing, recent, relief, similarly, address, alliance, app, block, canada, circumstances, competition, consideration, explore, gun, ladder, reaction, responsible, styles, boat, books, brothers, cultures, developed, effected, english, enter, forth, fruits, heads, list, philosophers, previously, sell, sentences, speed, traits, classmates, compromise, conquer, entered, grey, lifetime, mexico, relevant, sculpture, theirs, wide, claimed\n",
      "\n",
      "11.  higher, lower, math, science, improve, increase, lowry, released, utopia, provide, proven, health, performance, advantages, disadvantages, alertness, beneficial, benefit, healthy, decision, step, benefits, huge, final, sides, advantage, mental, difference, issue, case, deal, major, elders, lois, choices, big\n",
      "\n",
      "12.  prussia, austria, wars, battles, colonization, win, king, attack, allies, colonists, eighteenth, 18th, frederick, saxony, fought, won, territory, natives, struggle, struggles, spain, taxes, trade, caused, fighting, battle, government, gain, control, fight, britain, france, countries, french, land, war, regional, mid, issues, european, century, british, power, global\n",
      "\n",
      "13.  shirt, outfit, required, uncomfortable, individuality, creativity, expression, esteem, cloths, colors, opinions, mandatory, outfits, revolt, planks, decide, chose, public, safer, appropriate, waste, spending, require, grade, elementary, worn, private, selves, freshman, senior, junior, code, coded, codes, teachers, lastly, safe, focused, unique, style, assigned, worry, bullied, shoes, comfortable, spend, usually, forced, pick, afford, allowed, personality, families, poor, focus, choose, pay, haiti, country, free\n",
      "\n",
      "14.  spoke, persuasive, conspirators, emotional, mainly, tries, appeal, device, funeral, alive, effective, congress, mark, marc, elements, ambition, shakespeare, authors, speakers, murder, victim, repetition, contains, countrymen, demanding, logic, william, diction, honorable, honourable, murdered, hath, rescuers, cassius, sarcastic, pause, stabbed, faithful, praise, crowd, stronger\n",
      "\n",
      "15.  lines, writes, harmony, peacefully, tribe, indian, response, builds, para, paragraph, african, native, describes, explains, wrote, writing, talks, groups, hero, ordinary, american, americans, indians, written, 2, 3, mesa, valley, share, sharing, burns, conflict, interest, understanding, minutes, hours, pitts, rosenblatt, plane, saved, 1, corn, tomorrow, high, middle, wasps, bruce, object, nest, earth, cruel, years, year, vision, visions, view, natural, text, article, source, support, brooks, narrator, settlers, quote, note, peace, main, susan, true, human, old, young, character, b., spanish, hopi, seeds, moki, second, author, nature, live, :\n",
      "\n",
      "20.  expensive, cost, stop, prevent, uniform, clothing, children, student, nt, wo, express, dress, bullying, parents, wearing, buy, clothes, schools, money\n",
      "\n",
      "21.  waiting, waited, takes, taken, wait, looked, felt, talking, talk, told, asked, learn, understand, found, decided, laugh, laughing, naps, nap, finally, later, taking, act, line, thought, knew, patience, patient, looking, happened, happen, gave, lost, end, times, came, saw, tell, let, took, started, start, trying, wanted, making, friends, friend, got, went, night, class, find, ;, actually, work, hard, getting, come, home, family, little, laughter, right, long, said, sleep\n",
      "\n",
      "22.  hear, sing, langston, walt, whitman, hughes, singing, poem, america\n",
      "\n",
      "23.  society, community, says, saying, idea, point, reason, conclusion, brutus, antony, ways, example, believe, away, place, use, uses, having, world, lives, shows, story, states, speech, caesar\n",
      "\n",
      "25.  great, best, important, makes, able, need, feel, look, lot, save, know, going, good, bad, new, want, things, thing, better, person, think, time, day, different, way, help, life, like\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, group in enumerate(groups):\n",
    "    if len(groups[group]) < 5:\n",
    "        continue\n",
    "    print(f'{i+1}. ', ', '.join(groups[group][:100]))  # str(len(groups[group])).rjust(5), \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855a30de-959c-4dcf-8fd7-40703fb48545",
   "metadata": {},
   "source": [
    "## Group names\n",
    "\n",
    "1. Miscellaneous Actions: This list contains a mix of actions that do not have a specific relationship with one another. Some are actions such as \"jumped\" and \"fell\" while others are verbs like \"grabbed\" and \"watched.\" Additionally, there are words that can be categorized as places (\"washington,\" \"city\") and words that can be categorized as feelings (\"scared,\" \"excited\"). This list is a mix of different actions and feelings that do not fit into any particular category.\n",
    "\n",
    "1. Historical Agriculture and Numbers: This list includes words related to farming and agriculture, such as \"melons,\" \"plants,\" and \"crops.\" The list also contains specific numbers and names, including \"7,\" \"30,\" and \"ceasar.\" This list seems to be centered around agriculture in a historical context.\n",
    "\n",
    "1. Personal Growth and Social Media: This list contains words that relate to personal growth, such as \"achieve,\" \"complete,\" and \"prepared.\" It also includes words related to education (\"colleges,\" \"education\"), technology (\"facebook,\" \"internet\"), and emotions (\"annoying,\" \"happier\"). This list is related to personal growth and development, including education, technology, and emotions.\n",
    "\n",
    "1. Natural Disasters and Phenomena: This list contains words related to natural disasters and phenomena, such as \"storm,\" \"hurricane,\" and \"wind.\" It also includes words related to emotions (\"sadness,\" \"soul\") and other items that may be present during a natural disaster (\"trash,\" \"deed\"). This list is related to natural disasters and the emotions that come with them.\n",
    "\n",
    "1. Memorials and Representations: This list includes words related to memorials and representations, such as \"monuments,\" \"memorials,\" and \"possessions.\" It also includes words related to communication (\"communication,\" \"listen\") and other items that can be represented (\"animals,\" \"songs\"). This list seems to be related to memorials and the items and feelings that can be represented through them.\n",
    "\n",
    "1. Death and Emotion: This list contains words related to death and emotion, such as \"kill,\" \"death,\" and \"heart.\" It also includes words related to literature (\"poems,\" \"words\") and ancient history (\"roman,\" \"julius\"). This list seems to be related to death and the emotions and literature surrounding it.\n",
    "\n",
    "1. Rhetorical Devices: This list contains words related to rhetorical devices, such as \"pathos,\" \"ethos,\" and \"logos.\" It also includes words related to literature (\"ads,\" \"advertisements\") and politics (\"citizens,\" \"government\"). This list is related to rhetorical devices and their use in literature and politics.\n",
    "\n",
    "1. Events and Personal Growth: This list includes words related to events and personal growth, such as \"success,\" \"tragedy,\" and \"search.\" It also includes words related to emotion (\"fear,\" \"anger\") and geography (\"britian,\" \"europe\"). This list is related to personal growth and development through the events and experiences that shape it.\n",
    "\n",
    "1. Fashion and Self-Expression: This list contains words related to fashion and self-expression, such as \"cloths,\" \"colors,\" and \"personality.\" It also includes words related to education (\"grade,\" \"teacher\") and economic status (\"poor,\" \"afford\"). This list is related to fashion and how it can be used for self-expression.\n",
    "\n",
    "1. Leadership and Conflict: This list contains words related to leadership and conflict, such as \"leader,\" \"enemies,\" and \"trading.\" It also includes words related to geography (\"planet,\" \"island\") and events (\"disasters,\" \"relief\"). This list is related to leadership and the conflicts that arise.\n",
    "\n",
    "1. Health and Performance: This set of words focuses on terms related to health and improvement, such as \"health,\" \"beneficial,\" and \"alertness,\" as well as terms associated with performance like \"improve\" and \"performance.\"\n",
    "\n",
    "1. War and Colonization: This set of words consists of terms related to wars, battles, and colonization, including names of countries involved such as Prussia, Austria, Britain, and France.\n",
    "\n",
    "1. Dress Code and Bullying: This set of words revolves around the topic of dress codes and the controversy around their implementation, including terms like \"mandatory,\" \"forced,\" and \"safe,\" as well as terms related to bullying such as \"worry,\" \"bullied,\" and \"afford.\"\n",
    "\n",
    "1. Persuasive Speaking: This set of words consists of terms related to persuasive speaking, including techniques such as \"repetition\" and \"emotional appeal,\" as well as notable figures like Shakespeare and his character Cassius.\n",
    "\n",
    "1. Writing and Communication: This set of words revolves around writing and communication, including terms such as \"lines,\" \"paragraph,\" and \"article,\" as well as terms related to culture like \"Hopi\" and \"Spanish.\"\n",
    "\n",
    "20\\. School Uniforms and Bullying Prevention: This set of words consists of terms related to school uniforms and the debate around their effectiveness in preventing bullying, including terms like \"uniform,\" \"bullying,\" and \"cost.\"\n",
    "\n",
    "21\\. Patience and Waiting: This set of words focuses on the theme of patience and waiting, including terms like \"wait,\" \"patience,\" and \"took.\"\n",
    "\n",
    "22\\. Poetry and Singing: This set of words consists of terms related to poetry and singing, including names of notable poets like Langston Hughes and Walt Whitman.\n",
    "\n",
    "23\\. Reasoning and Persuasion: This set of words revolves around the theme of reasoning and persuasion, including terms like \"idea,\" \"reason,\" and \"speech.\"\n",
    "\n",
    "25\\. General Descriptors: This set of words includes general descriptors and common terms used to describe things, including words like \"great,\" \"important,\" and \"different.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8052bd73-bafe-4ff9-81fc-5a5e73d1b4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.      1 ['people']\n",
      " 1.      1 ['like']\n",
      " 2.      1 ['school']\n",
      " 3.      1 ['uniforms']\n",
      " 4.      1 ['time']\n",
      " 5.      1 ['life']\n",
      " 6.      1 ['man']\n",
      " 7.      1 ['things']\n",
      " 8.      1 ['way']\n",
      " 9.      1 ['think']\n",
      "10.      1 ['person']\n",
      "11.      1 ['good']\n",
      "12.      1 ['day']\n",
      "13.      1 ['said']\n",
      "14.      1 ['house']\n",
      "15.      1 ['want']\n",
      "16.      1 ['students']\n",
      "17.      1 ['help']\n",
      "18.      1 ['know']\n",
      "19.      1 ['wear']\n",
      "20.      1 ['different']\n",
      "21.      1 ['kids']\n",
      "22.      1 ['thing']\n",
      "23.      1 ['going']\n",
      "24.      1 ['america']\n",
      "25.      1 ['caesar']\n",
      "26.      1 ['got']\n",
      "27.      1 ['wasp']\n",
      "28.      1 ['brutus']\n",
      "29.      1 ['feel']\n",
      "30.      1 ['able']\n",
      "31.      1 ['world']\n",
      "32.      1 ['better']\n",
      "33.      1 ['shows']\n",
      "34.      1 ['society']\n",
      "35.      1 ['right']\n",
      "36.      1 ['story']\n",
      "37.      1 ['need']\n",
      "38.      1 ['poem']\n",
      "39.      1 ['water']\n",
      "40.      1 ['look']\n",
      "41.      1 ['new']\n",
      "42.      1 ['whitman']\n",
      "43.      1 ['went']\n",
      "44.      1 ['laughter']\n",
      "45.      1 ['british']\n",
      "46.      1 ['having']\n",
      "47.      1 ['antony']\n",
      "48.      1 ['hughes']\n",
      "49.      1 ['example']\n",
      "50.      1 ['speech']\n",
      "51.      1 ['friends']\n",
      "52.      1 ['social']\n",
      "53.      1 ['use']\n",
      "54.      1 ['live']\n",
      "55.      1 ['power']\n",
      "56.      1 ['bad']\n",
      "57.      1 ['lot']\n",
      "58.      1 ['clothes']\n",
      "59.      1 ['moki']\n",
      "60.      1 ['believe']\n",
      "61.      1 ['money']\n",
      "62.      1 ['nature']\n",
      "63.      1 ['self']\n",
      "64.      1 ['important']\n",
      "65.      1 ['ownership']\n",
      "66.      1 ['sleep']\n",
      "67.      1 ['community']\n",
      "68.      1 ['black']\n",
      "69.      1 ['great']\n",
      "70.      1 ['work']\n",
      "71.      1 [';']\n",
      "72.      1 ['women']\n",
      "73.      1 ['away']\n",
      "74.      1 ['says']\n",
      "75.      1 ['author']\n",
      "76.      1 ['spanish']\n",
      "77.      1 [':']\n",
      "78.      1 ['patience']\n",
      "79.      1 ['reason']\n",
      "80.      1 ['started']\n",
      "81.      1 ['media']\n",
      "82.      1 ['love']\n",
      "83.      1 ['come']\n",
      "84.      1 ['makes']\n",
      "85.      1 ['lives']\n",
      "86.      1 ['family']\n",
      "87.      1 ['little']\n",
      "88.      1 ['thought']\n",
      "89.      1 ['long']\n",
      "90.      1 ['best']\n",
      "91.      1 ['place']\n",
      "92.      1 ['parents']\n",
      "93.      1 ['states']\n",
      "94.      1 ['college']\n",
      "95.      1 ['find']\n",
      "96.      1 ['getting']\n",
      "97.      1 ['trying']\n",
      "98.      1 ['salim']\n",
      "99.      1 ['old']\n",
      "100.      1 ['schools']\n",
      "101.      1 ['wanted']\n",
      "102.      1 ['friend']\n",
      "103.      1 ['came']\n",
      "104.      1 ['hopi']\n",
      "105.      1 ['hard']\n",
      "106.      1 ['idea']\n",
      "107.      1 ['children']\n",
      "108.      1 ['french']\n",
      "109.      1 ['home']\n",
      "110.      1 ['laugh']\n",
      "111.      1 ['told']\n",
      "112.      1 ['night']\n",
      "113.      1 ['end']\n",
      "114.      1 ['wearing']\n",
      "115.      1 ['took']\n",
      "116.      1 ['saw']\n",
      "117.      1 ['patient']\n",
      "118.      1 ['singing']\n",
      "119.      1 ['britain']\n",
      "120.      1 ['land']\n",
      "121.      1 ['freedom']\n",
      "122.      1 ['making']\n",
      "123.      1 ['seeds']\n",
      "124.      1 ['start']\n",
      "125.      1 ['hear']\n",
      "126.      1 ['naps']\n",
      "127.      1 ['ways']\n",
      "128.      1 ['sense']\n",
      "129.      1 ['conclusion']\n",
      "130.      1 ['war']\n",
      "131.      1 ['years']\n",
      "132.      1 ['vision']\n",
      "133.      1 ['year']\n",
      "134.      1 ['brooks']\n",
      "135.      1 ['tell']\n",
      "136.      1 ['high']\n",
      "137.      1 ['let']\n",
      "138.      1 ['times']\n",
      "139.      1 ['knew']\n",
      "140.      1 ['happened']\n",
      "141.      1 ['uses']\n",
      "142.      1 ['narrator']\n",
      "143.      1 ['real']\n",
      "144.      1 ['saying']\n",
      "145.      1 ['second']\n",
      "146.      1 ['point']\n",
      "147.      1 ['citizens']\n",
      "148.      1 ['eye']\n",
      "149.      1 ['robes']\n",
      "150.      1 ['looked']\n",
      "151.      1 ['class']\n",
      "152.      1 ['gave']\n",
      "153.      1 ['kat']\n",
      "154.      1 ['save']\n",
      "155.      1 ['actually']\n",
      "156.      1 ['mom']\n",
      "157.      1 ['true']\n",
      "158.      1 ['phone']\n",
      "159.      1 ['play']\n",
      "160.      1 ['laughing']\n",
      "161.      1 ['finally']\n",
      "162.      1 ['identity']\n",
      "163.      1 ['instead']\n",
      "164.      1 ['visions']\n",
      "165.      1 ['happy']\n",
      "166.      1 ['france']\n",
      "167.      1 ['looking']\n",
      "168.      1 ['talking']\n",
      "169.      1 ['ads']\n",
      "170.      1 ['country']\n",
      "171.      1 ['peace']\n",
      "172.      1 ['big']\n",
      "173.      1 ['learn']\n",
      "174.      1 ['nt']\n",
      "175.      1 ['express']\n",
      "176.      1 ['fact']\n",
      "177.      1 ['rights']\n",
      "178.      1 ['negative']\n",
      "179.      1 ['source']\n",
      "180.      1 ['uniform']\n",
      "181.      1 ['talk']\n",
      "182.      1 ['lost']\n",
      "183.      1 ['try']\n",
      "184.      1 ['young']\n",
      "185.      1 ['room']\n",
      "186.      1 ['impact']\n",
      "187.      1 ['giver']\n",
      "188.      1 ['text']\n",
      "189.      1 ['2']\n",
      "190.      1 ['means']\n",
      "191.      1 ['owning']\n",
      "192.      1 ['buy']\n",
      "193.      1 ['found']\n",
      "194.      1 ['article']\n",
      "195.      1 ['character']\n",
      "196.      1 ['student']\n",
      "197.      1 ['men']\n",
      "198.      1 ['quote']\n",
      "199.      1 ['asked']\n",
      "200.      1 ['cause']\n",
      "201.      1 ['choice']\n",
      "202.      1 ['global']\n",
      "203.      1 ['human']\n",
      "204.      1 ['bullying']\n",
      "205.      1 ['positive']\n",
      "206.      1 ['wrong']\n",
      "207.      1 ['comes']\n",
      "208.      1 ['hand']\n",
      "209.      1 ['later']\n",
      "210.      1 ['nap']\n",
      "211.      1 ['certain']\n",
      "212.      1 ['left']\n",
      "213.      1 ['taking']\n",
      "214.      1 ['color']\n",
      "215.      1 ['support']\n",
      "216.      1 ['change']\n",
      "217.      1 ['future']\n",
      "218.      1 ['clothing']\n",
      "219.      1 ['countries']\n",
      "220.      1 ['fun']\n",
      "221.      1 ['issues']\n",
      "222.      1 ['personal']\n",
      "223.      1 ['1']\n",
      "224.      1 ['job']\n",
      "225.      1 ['seen']\n",
      "226.      1 ['interest']\n",
      "227.      1 ['boy']\n",
      "228.      1 ['minutes']\n",
      "229.      1 ['face']\n",
      "230.      1 ['ride']\n",
      "231.      1 ['mind']\n",
      "232.      1 ['decided']\n",
      "233.      1 ['game']\n",
      "234.      1 ['understand']\n",
      "235.      1 ['felt']\n",
      "236.      1 ['equal']\n",
      "237.      1 ['object']\n",
      "238.      1 ['hours']\n",
      "239.      1 ['happen']\n",
      "240.      1 ['stop']\n",
      "241.      1 ['objects']\n",
      "242.      1 ['wo']\n",
      "243.      1 ['feeling']\n",
      "244.      1 ['began']\n",
      "245.      1 ['waiting']\n",
      "246.      1 ['anthony']\n",
      "247.      1 ['jonas']\n",
      "248.      1 ['texting']\n",
      "249.      1 ['living']\n",
      "250.      1 ['body']\n",
      "251.      1 ['sure']\n",
      "252.      1 ['earth']\n",
      "253.      1 ['mean']\n",
      "254.      1 ['called']\n",
      "255.      1 ['helps']\n",
      "256.      1 ['american']\n",
      "257.      1 ['today']\n",
      "258.      1 ['given']\n",
      "259.      1 ['problems']\n",
      "260.      1 ['wasps']\n",
      "261.      1 ['matter']\n",
      "262.      1 ['reasons']\n",
      "263.      1 ['/']\n",
      "264.      1 ['thinking']\n",
      "265.      1 ['words']\n",
      "266.      1 ['situation']\n",
      "267.      1 ['care']\n",
      "268.      1 ['rome']\n",
      "269.      1 ['car']\n",
      "270.      1 ['main']\n",
      "271.      1 ['order']\n",
      "272.      1 ['wait']\n",
      "273.      1 ['feelings']\n",
      "274.      1 ['food']\n",
      "275.      1 ['heard']\n",
      "276.      1 ['strong']\n",
      "277.      1 ['monument']\n",
      "278.      1 ['problem']\n",
      "279.      1 ['3']\n",
      "280.      1 ['calling']\n",
      "281.      1 ['child']\n",
      "282.      1 ['door']\n",
      "283.      1 ['langston']\n",
      "284.      1 ['audience']\n",
      "285.      1 ['dress']\n",
      "286.      1 ['free']\n",
      "287.      1 ['dad']\n",
      "288.      1 ['indians']\n",
      "289.      1 ['needed']\n",
      "290.      1 ['act']\n",
      "291.      1 ['line']\n",
      "292.      1 ['haiti']\n",
      "293.      1 ['age']\n",
      "294.      1 ['americans']\n",
      "295.      1 ['hero']\n",
      "296.      1 ['helped']\n",
      "297.      1 ['chisholm']\n",
      "298.      1 ['group']\n",
      "299.      1 ['brother']\n",
      "300.      1 ['maybe']\n",
      "301.      1 ['small']\n",
      "302.      1 ['wants']\n",
      "303.      1 ['middle']\n",
      "304.      1 ['sing']\n",
      "305.      1 ['based']\n",
      "306.      1 ['inside']\n",
      "307.      1 ['kind']\n",
      "308.      1 ['pathos']\n",
      "309.      1 ['stay']\n",
      "310.      1 ['tone']\n",
      "311.      1 ['control']\n",
      "312.      1 ['soon']\n",
      "313.      1 ['everyday']\n",
      "314.      1 ['tried']\n",
      "315.      1 ['funny']\n",
      "316.      1 ['gives']\n",
      "317.      1 ['grow']\n",
      "318.      1 ['moment']\n",
      "319.      1 ['advertisements']\n",
      "320.      1 ['european']\n",
      "321.      1 ['heart']\n",
      "322.      1 ['type']\n",
      "323.      1 ['goes']\n",
      "324.      1 ['walt']\n",
      "325.      1 ['purpose']\n",
      "326.      1 ['working']\n",
      "327.      1 ['information']\n",
      "328.      1 ['shown']\n",
      "329.      1 ['similar']\n",
      "330.      1 ['understanding']\n",
      "331.      1 ['choose']\n",
      "332.      1 ['fight']\n",
      "333.      1 ['head']\n",
      "334.      1 ['morning']\n",
      "335.      1 ['attention']\n",
      "336.      1 ['century']\n",
      "337.      1 ['learned']\n",
      "338.      1 ['memorial']\n",
      "339.      1 ['pay']\n",
      "340.      1 ['rest']\n",
      "341.      1 ['turn']\n",
      "342.      1 ['view']\n",
      "343.      1 ['equality']\n",
      "344.      1 ['probably']\n",
      "345.      1 ['takes']\n",
      "346.      1 ['experience']\n",
      "347.      1 ['pitts']\n",
      "348.      1 ['focus']\n",
      "349.      1 ['kept']\n",
      "350.      1 ['jobs']\n",
      "351.      1 ['rules']\n",
      "352.      1 ['expensive']\n",
      "353.      1 ['days']\n",
      "354.      1 ['eyes']\n",
      "355.      1 ['humans']\n",
      "356.      1 ['language']\n",
      "357.      1 ['poems']\n",
      "358.      1 ['remember']\n",
      "359.      1 ['theme']\n",
      "360.      1 ['prevent']\n",
      "361.      1 ['corn']\n",
      "362.      1 ['kid']\n",
      "363.      1 ['short']\n",
      "364.      1 ['logos']\n",
      "365.      1 ['loved']\n",
      "366.      1 ['regional']\n",
      "367.      1 ['taken']\n",
      "368.      1 ['overall']\n",
      "369.      1 ['nest']\n",
      "370.      1 ['personality']\n",
      "371.      1 ['tomorrow']\n",
      "372.      1 ['united']\n",
      "373.      1 ['early']\n",
      "374.      1 ['eat']\n",
      "375.      1 ['history']\n",
      "376.      1 ['death']\n",
      "377.      1 ['effect']\n",
      "378.      1 ['napping']\n",
      "379.      1 ['share']\n",
      "380.      1 ['eventually']\n",
      "381.      1 ['lead']\n",
      "382.      1 ['learning']\n",
      "383.      1 ['leave']\n",
      "384.      1 ['mother']\n",
      "385.      1 ['speeches']\n",
      "386.      1 ['coming']\n",
      "387.      1 ['everybody']\n",
      "388.      1 ['past']\n",
      "389.      1 ['team']\n",
      "390.      1 ['advertising']\n",
      "391.      1 ['create']\n",
      "392.      1 ['note']\n",
      "393.      1 ['chance']\n",
      "394.      1 ['design']\n",
      "395.      1 ['relationship']\n",
      "396.      1 ['cruel']\n",
      "397.      1 ['outside']\n",
      "398.      1 ['ready']\n",
      "399.      1 ['word']\n",
      "400.      1 ['mesa']\n",
      "401.      1 ['plane']\n",
      "402.      1 ['saved']\n",
      "403.      1 ['showing']\n",
      "404.      1 ['talks']\n",
      "405.      1 ['bring']\n",
      "406.      1 ['clearly']\n",
      "407.      1 ['evidence']\n",
      "408.      1 ['usually']\n",
      "409.      1 ['allowed']\n",
      "410.      1 ['settlers']\n",
      "411.      1 ['truly']\n",
      "412.      1 ['open']\n",
      "413.      1 ['event']\n",
      "414.      1 ['government']\n",
      "415.      1 ['thoughts']\n",
      "416.      1 ['yes']\n",
      "417.      1 ['ask']\n",
      "418.      1 ['fighting']\n",
      "419.      1 ['gets']\n",
      "420.      1 ['opinion']\n",
      "421.      1 ['set']\n",
      "422.      1 ['book']\n",
      "423.      1 ['families']\n",
      "424.      1 ['knowledge']\n",
      "425.      1 ['meaning']\n",
      "426.      1 ['stated']\n",
      "427.      1 ['allow']\n",
      "428.      1 ['killed']\n",
      "429.      1 ['giving']\n",
      "430.      1 ['message']\n",
      "431.      1 ['rosenblatt']\n",
      "432.      1 ['burns']\n",
      "433.      1 ['voice']\n",
      "434.      1 ['walked']\n",
      "435.      1 ['african']\n",
      "436.      1 ['cold']\n",
      "437.      1 ['happiness']\n",
      "438.      1 ['poor']\n",
      "439.      1 ['showed']\n",
      "440.      1 ['stuff']\n",
      "441.      1 ['trade']\n",
      "442.      1 ['bed']\n",
      "443.      1 ['ethos']\n",
      "444.      1 ['far']\n",
      "445.      1 ['mad']\n",
      "446.      1 ['conflict']\n",
      "447.      1 ['knowing']\n",
      "448.      1 ['ones']\n",
      "449.      1 ['london']\n",
      "450.      1 ['playing']\n",
      "451.      1 ['sharing']\n",
      "452.      1 ['sister']\n",
      "453.      1 ['die']\n",
      "454.      1 ['wrote']\n",
      "455.      1 ['cost']\n",
      "456.      1 ['gone']\n",
      "457.      1 ['valley']\n",
      "458.      1 ['natural']\n",
      "459.      1 ['ran']\n",
      "460.      1 ['struggle']\n",
      "461.      1 ['waited']\n",
      "462.      1 ['ambitious']\n",
      "463.      1 ['caused']\n",
      "464.      1 ['major']\n",
      "465.      1 ['susan']\n",
      "466.      1 ['actions']\n",
      "467.      1 ['beautiful']\n",
      "468.      1 ['girl']\n",
      "469.      1 ['company']\n",
      "470.      1 ['close']\n",
      "471.      1 ['especially']\n",
      "472.      1 ['brought']\n",
      "473.      1 ['hurt']\n",
      "474.      1 ['spend']\n",
      "475.      1 ['skills']\n",
      "476.      1 ['4']\n",
      "477.      1 ['5']\n",
      "478.      1 ['according']\n",
      "479.      1 ['begin']\n",
      "480.      1 ['dead']\n",
      "481.      1 ['simple']\n",
      "482.      1 ['case']\n",
      "483.      1 ['events']\n",
      "484.      1 ['items']\n",
      "485.      1 ['needs']\n",
      "486.      1 ['nice']\n",
      "487.      1 ['enjoy']\n",
      "488.      1 ['ideas']\n",
      "489.      1 ['lose']\n",
      "490.      1 ['white']\n",
      "491.      1 ['ability']\n",
      "492.      1 ['telling']\n",
      "493.      1 ['choices']\n",
      "494.      1 ['completely']\n",
      "495.      1 ['perfect']\n",
      "496.      1 ['struggles']\n",
      "497.      1 ['easier']\n",
      "498.      1 ['elders']\n",
      "499.      5 ['grade', 'elementary', 'freshman', 'senior', 'junior']\n",
      "500.      1 ['helping']\n",
      "501.      1 ['hope']\n",
      "502.      1 ['realized']\n",
      "503.      1 ['shirley']\n",
      "504.      1 ['bruce']\n",
      "505.      1 ['teacher']\n",
      "506.      1 ['describes']\n",
      "507.      1 ['longer']\n",
      "508.      1 ['mid']\n",
      "509.      1 ['known']\n",
      "510.      1 ['likely']\n",
      "511.      1 ['police']\n",
      "512.      1 ['realize']\n",
      "513.      1 ['gain']\n",
      "514.      1 ['send']\n",
      "515.      1 ['battle']\n",
      "516.      1 ['question']\n",
      "517.      1 ['easy']\n",
      "518.      1 ['games']\n",
      "519.      1 ['groups']\n",
      "520.      1 ['stand']\n",
      "521.      1 ['happens']\n",
      "522.      1 ['treated']\n",
      "523.      1 ['unique']\n",
      "524.      1 ['week']\n",
      "525.      1 ['simply']\n",
      "526.      1 ['tells']\n",
      "527.      1 ['course']\n",
      "528.      1 ['deep']\n",
      "529.      1 ['moved']\n",
      "530.      2 ['rhetorical', 'literary']\n",
      "531.      1 ['s']\n",
      "532.      1 ['thinks']\n",
      "533.      1 ['agree']\n",
      "534.      1 ['argument']\n",
      "535.      1 ['explains']\n",
      "536.      2 ['wars', 'battles']\n",
      "537.      1 ['physical']\n",
      "538.      1 ['result']\n",
      "539.      1 ['sat']\n",
      "540.      8 ['air', 'sleeping', 'laughs', 'news', 'gift', 'sounds', 'sounded', 'stalk']\n",
      "541.      1 ['clear']\n",
      "542.      1 ['created']\n",
      "543.      1 ['sound']\n",
      "544.      1 ['spain']\n",
      "545.      1 ['stress']\n",
      "546.      1 ['pick']\n",
      "547.      1 ['pretty']\n",
      "548.      1 ['sad']\n",
      "549.      1 ['huge']\n",
      "550.      1 ['looks']\n",
      "551.      1 ['run']\n",
      "552.      1 ['sameness']\n",
      "553.      1 ['skill']\n",
      "554.      1 ['territory']\n",
      "555.      1 ['ordinary']\n",
      "556.      1 ['process']\n",
      "557.      1 ['turned']\n",
      "558.      1 ['worry']\n",
      "559.      1 ['b.']\n",
      "560.      1 ['calm']\n",
      "561.      1 ['emotions']\n",
      "562.      2 ['reader', 'readers']\n",
      "563.      1 ['break']\n",
      "564.      2 ['online', 'advertisement']\n",
      "565.      1 ['follow']\n",
      "566.      1 ['hit']\n",
      "567.      1 ['hold']\n",
      "568.      1 ['hour']\n",
      "569.      1 ['possible']\n",
      "570.      1 ['common']\n",
      "571.      1 ['dark']\n",
      "572.      2 ['improve', 'increase']\n",
      "573.      1 ['written']\n",
      "574.      1 ['fast']\n",
      "575.      1 ['light']\n",
      "576.      1 ['lived']\n",
      "577.      1 ['laughed']\n",
      "578.      1 ['structure']\n",
      "579.      1 ['fall']\n",
      "580.      1 ['figure']\n",
      "581.      1 ['native']\n",
      "582.      1 ['safe']\n",
      "583.      1 ['shoes']\n",
      "584.      2 ['tangible', 'intangible']\n",
      "585.      1 ['bit']\n",
      "586.      1 ['bullied']\n",
      "587.      1 ['individual']\n",
      "588.      1 ['interested']\n",
      "589.      1 ['led']\n",
      "590.      3 ['plato', 'aristotle', 'sartre']\n",
      "591.      2 ['eighteenth', '18th']\n",
      "592.      1 ['para']\n",
      "593.      1 ['wake']\n",
      "594.      1 ['writing']\n",
      "595.      1 ['brain']\n",
      "596.      1 ['deal']\n",
      "597.      1 ['ended']\n",
      "598.      1 ['natives']\n",
      "599.      1 ['trouble']\n",
      "600.      2 ['walking', 'walk']\n",
      "601.      1 ['watch']\n",
      "602.      1 ['beginning']\n",
      "603.      5 ['curiosity', 'finds', 'curious', 'discovers', 'intrigued']\n",
      "604.      1 ['starting']\n",
      "605.      1 ['tired']\n",
      "606.      1 ['plan']\n",
      "607.      1 ['built']\n",
      "608.      1 ['difference']\n",
      "609.      1 ['difficult']\n",
      "610.      1 ['entire']\n",
      "611.      1 ['powerful']\n",
      "612.      2 ['river', 'survivors']\n",
      "613.     16 ['born', 'taught', 'supposed', 'planned', 'threw', 'presents', 'lessons', 'liberty', 'equally', 'sunny']\n",
      "614.      1 ['ground']\n",
      "615.      1 ['key']\n",
      "616.      1 ['seeing']\n",
      "617.      1 ['speak']\n",
      "618.      1 ['issue']\n",
      "619.      4 ['kill', 'killing', 'cried', 'bury']\n",
      "620.      3 ['public', 'safer', 'private']\n",
      "621.      1 ['starts']\n",
      "622.      1 ['build']\n",
      "623.      1 ['claim']\n",
      "624.     10 ['floor', 'yelled', 'grabbed', 'answered', 'missing', 'sky', 'impossible', 'waters', 'yell', 'handed']\n",
      "625.      1 ['multiple']\n",
      "626.      1 ['workers']\n",
      "627.      1 ['—']\n",
      "628.      2 ['grew', 'grown']\n",
      "629.      1 ['growing']\n",
      "630.      1 ['knows']\n",
      "631.      6 ['facebook', 'instagram', 'pop', 'twitter', 'youtube', 'snapchat']\n",
      "632.      1 ['feels']\n",
      "633.      1 ['goods']\n",
      "634.      3 ['lowry', 'released', 'utopia']\n",
      "635.      1 ['normal']\n",
      "636.      2 ['quickly', 'hair']\n",
      "637.      6 ['violence', 'decrease', 'cliques', 'reduce', 'prevents', 'cyber']\n",
      "638.      1 ['watching']\n",
      "639.      3 ['7', '9', '8']\n",
      "640.      1 ['allows']\n",
      "641.      2 ['communicate', 'communication']\n",
      "642.      1 ['crazy']\n",
      "643.      1 ['died']\n",
      "644.      1 ['extremely']\n",
      "645.      1 ['kitchen']\n",
      "646.      2 ['persuade', 'convince']\n",
      "647.      2 ['appeals', 'devices']\n",
      "648.      1 ['changed']\n",
      "649.      1 ['forced']\n",
      "650.      1 ['fought']\n",
      "651.      1 ['god']\n",
      "652.      1 ['period']\n",
      "653.      2 ['allies', 'colonists']\n",
      "654.      1 ['benefits']\n",
      "655.      1 ['boring']\n",
      "656.      1 ['darker']\n",
      "657.      1 ['father']\n",
      "658.      1 ['forget']\n",
      "659.      5 ['worried', 'scared', 'excited', 'confused', 'impatient']\n",
      "660.      1 ['nation']\n",
      "661.      2 ['okay', \"''\"]\n",
      "662.      2 ['running', 'acting']\n",
      "663.      5 ['slowly', 'rope', 'cream', 'flotation', 'floatation']\n",
      "664.      1 ['decision']\n",
      "665.      4 ['location', 'size', 'materials', 'lincoln']\n",
      "666.      1 ['passengers']\n",
      "667.      4 ['prussia', 'austria', 'frederick', 'saxony']\n",
      "668.      1 ['teachers']\n",
      "669.      1 ['10']\n",
      "670.      1 ['beneficial']\n",
      "671.      1 ['blue']\n",
      "672.      1 ['crowd']\n",
      "673.      2 ['disasters', 'disaster']\n",
      "674.      2 ['energy', 'studies']\n",
      "675.      1 ['individuals']\n",
      "676.      1 ['late']\n",
      "677.      1 ['passed']\n",
      "678.      2 ['read', 'fiction']\n",
      "679.      1 ['style']\n",
      "680.      1 ['won']\n",
      "681.    538 ['non', 'storm', 'statue', 'placed', 'greatly', 'shape', 'columbus', 'described', 'wind', 'hurricanes']\n",
      "682.      1 ['afford']\n",
      "683.      1 ['amazing']\n",
      "684.      1 ['examples']\n",
      "685.      2 ['king', 'attack']\n",
      "686.      2 ['summer', 'christmas']\n",
      "687.      1 ['couple']\n",
      "688.      2 ['effective', 'congress']\n",
      "689.      1 ['excerpt']\n",
      "690.      5 ['hands', 'race', 'greed', 'beings', 'corruption']\n",
      "691.      1 ['material']\n",
      "692.      1 ['respect']\n",
      "693.     16 ['season', 'related', 'occurred', 'technology', 'relate', 'wealth', 'tension', 'faces', 'friendships', 'unfortunately']\n",
      "694.      1 ['check']\n",
      "695.      1 ['develop']\n",
      "696.      3 ['girls', 'boys', 'agency']\n",
      "697.      1 ['upset']\n",
      "698.      1 ['woman']\n",
      "699.      2 ['define', 'detrimental']\n",
      "700.      2 ['joke', 'jokes']\n",
      "701.      1 ['lastly']\n",
      "702.      1 ['noticed']\n",
      "703.      1 ['slaves']\n",
      "704.      1 ['vote']\n",
      "705.      1 ['benefit']\n",
      "706.      1 ['powers']\n",
      "707.      5 ['topic', 'center', 'occur', 'wary', 'attracting']\n",
      "708.      1 ['angry']\n",
      "709.      1 ['comfortable']\n",
      "710.      1 ['cool']\n",
      "711.      4 ['easily', 'valuable', 'proficient', 'thoroughly']\n",
      "712.      1 ['exactly']\n",
      "713.      4 ['form', 'determine', 'owned', 'item']\n",
      "714.      2 ['internet', 'ad']\n",
      "715.      2 ['sources', 'document']\n",
      "716.      3 ['state', 'messages', 'messaging']\n",
      "717.      1 ['store']\n",
      "718.      1 ['anymore']\n",
      "719.     11 ['losing', 'loss', 'debt', 'doctor', 'cycle', 'foundation', 'schedule', 'recommended', 'habits', 'deprived']\n",
      "720.      2 ['farm', 'barn']\n",
      "721.      1 ['half']\n",
      "722.      2 ['lines', 'writes']\n",
      "723.      1 ['minute']\n",
      "724.      1 ['paragraph']\n",
      "725.      1 ['tribe']\n",
      "726.   6015 ['enemies', 'territories', 'ball', 'conflicts', 'spot', 'leader', 'friendly', 'position', 'sight', 'crown']\n",
      "727.      2 ['crash', 'crashed']\n",
      "728.      3 ['europe', 'affected', 'impacted']\n",
      "729.     22 ['park', 'cars', 'riding', 'fire', 'crying', 'cry', 'dying', 'slow', 'names', 'yelling']\n",
      "730.      1 ['places']\n",
      "731.      2 ['possessions', 'possession']\n",
      "732.      3 ['table', 'india', 'kitchen/']\n",
      "733.      5 ['shopping', 'extra', 'spent', 'wash', 'dirty']\n",
      "734.      1 ['connection']\n",
      "735.      1 ['fair']\n",
      "736.      1 ['finding']\n",
      "737.      1 ['garden']\n",
      "738.      2 ['listen', 'trust']\n",
      "739.      1 ['response']\n",
      "740.      1 ['secret']\n",
      "741.      1 ['instance']\n",
      "742.    222 ['mention', 'worst', 'unfair', 'popular', 'smart', 'wonderful', 'greatest', 'liked', 'cut', 'desire']\n",
      "743.      2 ['mark', 'marc']\n",
      "744.      1 ['romans']\n",
      "745.      1 ['sides']\n",
      "746.      1 ['step']\n",
      "747.      1 ['tend']\n",
      "748.      3 ['value', 'materialistic', 'extends']\n",
      "749.      1 ['video']\n",
      "750.      1 ['weeks']\n",
      "751.      3 ['area', 'areas', 'parts']\n",
      "752.      4 ['ashamed', 'north', 'sings', 'voices']\n",
      "753.      1 ['emotion']\n",
      "754.      1 ['proves']\n",
      "755.      2 ['lots', 'rich']\n",
      "756.      8 ['straight', '$', 'leaves', 'bought', 'pair', 'parent', 'dollars', '249']\n",
      "757.      2 ['arrived', 'mouths']\n",
      "758.      5 ['blood', 'beating', 'beat', 'disease', 'coffin']\n",
      "759.      1 ['builds']\n",
      "760.      2 ['decide', 'chose']\n",
      "761.      2 ['imagine', 'political']\n",
      "762.      3 ['including', 'defend', 'push']\n",
      "763.      4 ['large', 'considering', 'significant', 'intentional']\n",
      "764.      1 ['worth']\n",
      "765.      1 ['6']\n",
      "766.      1 ['advantage']\n",
      "767.      3 ['sitting', 'mans', 'tobacco']\n",
      "768.      1 ['affect']\n",
      "769.      1 ['answer']\n",
      "770.      1 ['argue']\n",
      "771.      1 ['capsule']\n",
      "772.      5 ['fit', 'task', 'solution', 'option', 'medicine']\n",
      "773.      4 ['memory', 'detail', 'details', 'lakes']\n",
      "774.      1 ['named']\n",
      "775.      6 ['pain', 'happier', 'alert', 'groggy', 'guilty', 'refreshed']\n",
      "776.      1 ['situations']\n",
      "777.      1 ['stronger']\n",
      "778.     14 ['fear', 'anger', 'tears', 'effort', 'danger', 'o', 'relax', 'lowered', 'drought', 'mornings']\n",
      "779.      1 ['guy']\n",
      "780.      1 ['healthy']\n",
      "781.      2 ['higher', 'lower']\n",
      "782.     16 ['ice', 'pulled', 'tree', 'jumped', 'chair', 'snow', 'fish', 'classroom', 'freezing', 'jump']\n",
      "783.      3 ['influence', 'effects', 'impacts']\n",
      "784.      2 ['lack', 'national']\n",
      "785.      1 ['mental']\n",
      "786.      5 ['shirt', 'outfit', 'cloths', 'outfits', 'appropriate']\n",
      "787.      3 ['companies', 'advertisers', 'identities']\n",
      "788.      1 ['final']\n",
      "789.      1 ['freedoms']\n",
      "790.      4 ['loud', 'noise', 'scream', 'shriek']\n",
      "791.      1 ['memories']\n",
      "792.      1 ['peoples']\n",
      "793.    127 ['replied', 'oh', 'ok', 'followed', 'guys', 'perfectly', 'broken', 'sorry', 'son', 'coach']\n",
      "794.      1 ['roman']\n",
      "795.      4 ['sit', 'lay', 'east', 'laying']\n",
      "796.      2 ['waste', 'spending']\n",
      "797.      8 ['30', '20', '15', '25', 'thirty', '16', '24', '45']\n",
      "798.      2 ['advantages', 'disadvantages']\n",
      "799.     13 ['putting', 'happening', 'baby', 'peaceful', 'choosing', 'shelter', 'adult', 'makeup', 'plain', 't']\n",
      "800.      3 ['fell', 'stopped', 'falling']\n",
      "801.      1 ['focused']\n",
      "802.      4 ['homes', 'haitians', 'hive', 'houses']\n",
      "803.      1 ['honor']\n",
      "804.      2 ['meant', 'system']\n",
      "805.      8 ['reality', 'furthermore', 'conclude', 'strongly', 'protection', 'dig', 'vigil', 'swirls']\n",
      "806.      1 ['brings']\n",
      "807.      1 ['conversation']\n",
      "808.      4 ['destroyed', 'deserve', 'suffrage', 'occupy']\n",
      "809.      1 ['dreams']\n",
      "810.      2 ['goal', 'goals']\n",
      "811.      2 ['revolt', 'planks']\n",
      "812.      1 ['julius']\n",
      "813.     10 ['picture', 'pope', 'alike', 'imagination', 'thrice', 'committed', 'philosopher', 'pure', 'fellows', 'pursuit']\n",
      "814.      2 ['plants', 'crops']\n",
      "815.      1 ['taxes']\n",
      "816.      7 ['..', 'confidence', 'image', 'property', 'movement', 'mystery', 'amendment']\n",
      "817.      2 ['building', 'creating']\n",
      "818.      1 ['changes']\n",
      "819.     53 ['continue', 'wanting', 'obtain', 'struggling', 'avoid', 'ignore', 'treat', 'shore', 'advertise', 'maintain']\n",
      "820.      2 ['math', 'science']\n",
      "821.      1 ['single']\n",
      "822.      1 ['smile']\n",
      "823.      3 ['played', 'finished', 'plays']\n",
      "824.      2 ['song', 'proud']\n",
      "825.      1 ['sphere']\n",
      "826.      3 ['study', 'research', 'craft']\n",
      "827.      6 ['test', 'dog', 'movie', 'cat', 'movies', 'tv']\n",
      "828.      5 ['average', 'price', 'designer', 'afternoon', 'skilled']\n",
      "829.      2 ['describe', 'explaining']\n",
      "830.      1 ['holocaust']\n",
      "831.      1 ['indian']\n",
      "832.     21 ['interests', 'likes', 'owns', 'defined', 'values', 'characteristics', 'appearance', 'creative', 'defines', 'depending']\n",
      "833.      2 ['page', 'siddhartha']\n",
      "834.      7 ['products', 'product', 'business', 'brand', 'introduced', 'impose', 'reject']\n",
      "835.      1 ['questions']\n",
      "836.      8 ['special', 'brave', 'heroic', 'selfless', 'extraordinary', 'unknown', 'courageous', 'drag']\n",
      "837.      1 ['truth']\n",
      "838.      5 ['views', 'types', 'kinds', 'perspectives', 'meanings']\n",
      "839.      1 ['assigned']\n",
      "840.      2 ['colors', 'opinions']\n",
      "841.     14 ['funeral', 'alive', 'ambition', 'shakespeare', 'murder', 'victim', 'william', 'murdered', 'hath', 'cassius']\n",
      "842.      7 ['decisions', 'greater', 'matters', 'mistakes', 'organized', 'cliffs', 'distinctions']\n",
      "843.      6 ['favorite', 'regular', 'buying', 'wears', 'inappropriate', 'wore']\n",
      "844.      4 ['number', 'release', 'novel', 'assignment']\n",
      "845.      7 ['opened', 'standing', 'knocked', 'closed', 'shut', 'vulture', 'knock']\n",
      "846.      1 ['paper']\n",
      "847.      4 ['plant', 'planted', 'forbidden', 'planting']\n",
      "848.      2 ['prepare', 'preparing']\n",
      "849.      2 ['provide', 'proven']\n",
      "850.     10 ['letter', 'subject', 'allowing', 'subjects', 'bengali', 'charged', 'charging', 'exterminate', 'ransoms', 'republican']\n",
      "851.      4 ['specific', 'particular', 'cell', '37']\n",
      "852.      4 ['basically', 'pride', 'humor', 'unity']\n",
      "853.      2 ['constantly', 'forever']\n",
      "854.      3 ['force', 'fix', 'solve']\n",
      "855.      4 ['shared', 'joy', 'shortest', 'intricately']\n",
      "856.      8 ['leaving', 'notice', 'visit', 'exact', 'chat', 'funniest', 'studied', 'troubling']\n",
      "857.     82 ['facts', 'statement', 'points', 'leading', 'arguments', 'stating', 'demonstrates', 'reasoning', 'discrimination', 'beliefs']\n",
      "858.      2 ['older', 'younger']\n",
      "859.      1 ['saving']\n",
      "860.      2 ['earlier', 'held']\n",
      "861.      4 ['sent', 'watched', 'dare', 'captives']\n",
      "862.      2 ['adults', 'teens']\n",
      "863.      2 ['dream', 'lesson']\n",
      "864.      8 ['earthquake', 'tragedy', 'fields', '2010', 'struck', 'poorest', 'razed', 'catastrophes']\n",
      "865.      2 ['education', 'level']\n",
      "866.      2 ['expression', 'esteem']\n",
      "867.      3 ['path', 'stage', 'waking']\n",
      "868.      3 ['perspective', 'songs', 'compared']\n",
      "869.      2 ['bike', 'stood']\n",
      "870.      7 ['daily', 'risk', 'willing', 'risked', 'sacrifice', 'sacrificed', 'risking']\n",
      "871.     11 ['plans', ']', 'activities', 'aware', 'pants', 'plus', 'humble', 'puts', 'attend', 'dedicated']\n",
      "872.     18 ['offered', 'wish', 'gained', 'attempt', 'law', 'rise', 'military', 'empire', 'ruler', 'attacked']\n",
      "873.      3 ['caught', 'piece', 'paying']\n",
      "874.     11 ['field', 'eating', 'scene', 'seconds', 'months', '18', 'differently', '17', 'sooner', '14']\n",
      "875.      3 ['health', 'performance', 'alertness']\n",
      "876.     67 ['etc', 'city', 'road', 'town', 'dressed', 'stairs', 'hotel', 'weekend', 'computer', 'dinner']\n",
      "877.      7 ['success', 'successful', 'terms', 'changing', 'concept', 'discover', 'desperate']\n",
      "878.      4 ['claims', 'believes', 'believed', 'argues']\n",
      "879.      3 ['represents', 'represent', 'represented']\n",
      "880.      2 ['strange', 'crushed']\n",
      "881.      6 ['terrible', 'experienced', 'horrible', 'faced', 'tough', 'afraid']\n",
      "882.     11 ['suddenly', 'immediately', 'officer', 'partner', 'officers', 'office', 'neighbor', 'station', 'wife', 'neighbors']\n",
      "883.      4 ['talked', 'nervous', 'frustrated', 'pale']\n",
      "884.      3 ['works', 'worked', 'involved']\n",
      "885.      2 ['action', 'explained']\n",
      "886.      2 ['classes', 'personally']\n",
      "887.      7 ['colored', 'haitian', 'protect', 'distance', 'lifeline', 'indigenous', 'upheaval']\n",
      "888.      4 ['monuments', 'general', 'memorials', 'factors']\n",
      "889.      3 ['watermelon', 'melons', 'melon']\n",
      "890.     32 ['britian', 'bengal', 'forces', 'europeans', 'defeat', 'colonies', 'caribbean', 'region', 'defeated', 'manila']\n",
      "891.      2 ['harmony', 'peacefully']\n",
      "892.     11 ['importance', 'beauty', 'actual', 'historical', 'heroes', 'definition', 'significance', 'tragic', 'sacred', 'memorializing']\n",
      "893.      5 ['search', 'write', 'wonder', 'grab', 'forms']\n",
      "894.     11 ['notes', 'culture', 'fully', 'welcomed', 'missionaries', 'brutal', 'driven', 'explorers', 'outlawed', 'resent']\n",
      "895.      4 ['red', 'male', 'received', '1/2']\n",
      "896.      9 ['begins', 'speaks', 'adds', 'expresses', 'inspired', 'mentions', 'reveals', 'responds', 'shares']\n",
      "897.      6 ['connect', 'birthday', 'connected', 'friendship', 'connections', 'connects']\n",
      "898.      3 ['consider', 'considered', 'negatively']\n",
      "899.      3 ['definitely', 'obviously', 'u']\n",
      "900.      2 ['safety', 'reach']\n",
      "901.      2 ['sees', 'grows']\n",
      "902.      5 ['rid', 'skin', 'eliminating', 'eliminate', 'eliminates']\n",
      "903.      5 ['stuck', 'prepared', 'ahead', 'apply', 'accepted']\n",
      "904.      4 ['addition', 'resources', 'suffering', 'economic']\n",
      "905.      4 ['closer', 'silent', 'carols', 'lovers']\n",
      "906.      6 ['continued', 'supports', 'careful', 'happily', 'upper', 'atop']\n",
      "907.      3 ['differences', 'sort', 'similarities']\n",
      "908.      2 ['drive', 'drove']\n",
      "909.      3 ['faster', 'cousin', 'somebody']\n",
      "910.      1 ['include']\n",
      "911.      5 ['lets', 'letting', 'distraction', 'distract', 'violate']\n",
      "912.      1 ['fascinated']\n",
      "913.      1 ['moral']\n",
      "914.      3 ['opposite', 'pueblo', 'tear']\n",
      "915.      1 ['party']\n",
      "916.      6 ['colleges', 'hot', 'forward', 'clock', 'deeper', 'horse']\n",
      "917.      3 ['spoke', 'persuasive', 'conspirators']\n",
      "918.      1 ['roger']\n",
      "919.     16 ['survive', 'meet', 'overcome', 'identify', 'finish', 'handle', 'spread', 'escape', 'succeed', 'accomplish']\n",
      "920.      4 ['relationships', 'filled', 'guess', 'thanks']\n",
      "921.      2 ['explain', 'prove']\n",
      "922.      5 ['fine', 'courage', 'selflessness', 'heroism', 'stunning']\n",
      "923.      2 ['hidden', '1680']\n",
      "924.      2 ['ring', 'sign']\n",
      "925.      9 ['reading', 'mentioned', 'presented', 'unlike', 'sentence', 'relates', 'refuse', 'robust', 'honour']\n",
      "926.      4 ['role', 'aspects', 'factor', 'element']\n",
      "927.     21 ['gender', 'gotten', 'creates', 'keeping', 'continues', 'hoping', 'barely', 'limited', 'low', 'increases']\n",
      "928.      2 ['grades', 'evil']\n",
      "929.     10 ['music', 'sports', 'football', 'basketball', 'soccer', 'sport', 'players', 'baseball', 'player', 'hockey']\n",
      "930.      4 ['passage', 'essay', 'escaped', 'oftener']\n",
      "931.      2 ['pictures', 'quick']\n",
      "932.     13 ['dear', 'flight', 'mr.', 'washington', 'mall', '90', 'bridge', 'florida', 'mrs.', 'principal']\n",
      "933.      6 ['species', 'animals', 'complex', 'birds', 'animal', 'collective']\n",
      "934.      5 ['seven', '12', '11', 'hundreds', 'lasted']\n",
      "935.      5 ['stayed', 'winter', 'staying', 'bathroom', 'remain']\n",
      "936.      2 ['worse', 'confident']\n",
      "937.      5 ['environment', 'keeps', 'fashion', 'spirit', 'supplies']\n",
      "938.      8 ['appeal', 'device', 'elements', 'repetition', 'demanding', 'logic', 'diction', 'sarcastic']\n",
      "939.      2 ['ago', 'uneasy']\n",
      "940.     46 ['causes', 'causing', 'minds', 'famous', 'random', 'variety', 'bond', 'listening', 'behavior', 'cases']\n",
      "941.      3 ['code', 'coded', 'codes']\n",
      "942.      2 ['experiences', 'stories']\n",
      "943.      4 ['super', 'members', 'unit', 'member']\n",
      "944.      2 ['helicopter', 'rescue']\n",
      "945.     18 ['helpful', 'add', 'expected', 'teenagers', 'mess', 'useful', 'provided', 'added', 'throw', 'dangerous']\n",
      "946.      4 ['mood', 'moments', 'luck', 'quality']\n",
      "947.      6 ['picked', 'bully', 'bullies', 'judge', 'judged', 'distracted']\n",
      "948.      2 ['post', 'hearing']\n",
      "949.      3 ['practice', 'clean', 'tiny']\n",
      "950.      5 ['target', 'opportunity', 'receive', 'targeted', 'match']\n",
      "951.      8 ['ceasar', 'b', 'e', 'c', '#', 'f', 'd', 'g']\n",
      "952.      2 ['interesting', 'weird']\n",
      "953.      2 ['ultimately', 'determined']\n",
      "954.      2 ['honorable', 'honourable']\n",
      "955.      2 ['crime', 'leads']\n",
      "956.      4 ['emotional', 'mainly', 'tries', 'countrymen']\n",
      "957.      2 ['necessary', 'harder']\n",
      "958.      5 ['required', 'uncomfortable', 'mandatory', 'require', 'worn']\n",
      "959.     10 ['correct', 'pass', 'speaking', 'persons', 'loves', 'background', 'compare', 'factual', 'universal', 'foul']\n",
      "960.      3 ['individuality', 'creativity', 'selves']\n",
      "961.     73 ['met', 'near', 'reached', 'hanging', 'broke', 'holding', 'biggest', 'sun', 'catch', 'discovered']\n",
      "962.      5 ['moving', 'weather', 'driving', 'evening', 'passing']\n",
      "963.      1 ['paul']\n",
      "964.      3 ['planning', 'career', 'preparation']\n",
      "965.      2 ['jean', 'development']\n",
      "966.      6 ['shirts', 'possibly', '%', 'phones', '[', 'percent']\n",
      "967.      3 ['thank', 'annoying', 'box']\n",
      "968.     21 ['rule', 'laws', 'despite', 'accept', 'majority', 'obvious', 'diversity', 'holds', 'opportunities', 'controlled']\n",
      "969.      2 ['colonization', 'win']\n",
      "970.      4 ['trip', 'woke', 'term', 'periods']\n",
      "971.     98 ['homework', 'quiet', 'lunch', 'awake', 'warm', 'stomach', 'busy', 'hurricane', 'touch', 'expect']\n",
      "972.      4 ['gray', 'christopher', 'weep', 'tropical']\n",
      "973.      5 ['prejudice', 'female', 'discriminated', 'million', 'injured']\n",
      "974.     12 ['speaker', 'apart', 'constitution', 'blacks', 'inequality', 'mechanics', 'slave', 'hears', 'carpenter', 'boatman']\n",
      "975.      1 ['museum']\n",
      "976.      2 ['expressing', 'hate']\n",
      "977.      2 ['pitt', 'breath']\n",
      "978.      5 ['rude', 'networks', 'activity', 'function', 'status']\n",
      "979.      1 ['ticket']\n",
      "980.      1 ['leonard']\n",
      "981.      2 ['calls', 'till']\n",
      "982.      3 ['cared', 'asking', 'fellow']\n",
      "983.      2 ['following', 'present']\n",
      "984.      7 ['bloody', 'diane', 'gardens', 'kawayvatnga', '\\x80\\x94', 'seed', 'healing']\n",
      "985.      8 ['hide', 'boost', 'bright', 'strength', 'promote', 'gang', 'improved', 'restore']\n",
      "986.      4 ['authors', 'speakers', 'contains', 'rescuers']\n",
      "987.      3 ['asleep', 'sudden', 'suspended']\n",
      "988.      3 ['popé', 'provides', 'popăš']\n",
      "989.      2 ['citizen', 'population']\n",
      "990.      5 ['site', 'potomac', 'sites', 'account', 'sights']\n",
      "991.      6 ['religion', 'lands', 'alliances', 'nations', 'regions', 'york']\n",
      "992.      2 ['rebuild', 'churches']\n",
      "993.      3 ['belongs', 'varied', 'blithe']\n",
      "994.      2 ['stranger', 'strangers']\n",
      "995.      9 ['stem', 'melodious', 'committee', 'village', 'entering', 'measures', 'fashioned', 'inhabited', 'twilight']\n",
      "996.      1 ['lois']\n",
      "997.      2 ['achieve', 'complete']\n",
      "998.      5 ['teach', 'pressure', 'memorialize', 'volunteer', 'hideous']\n",
      "999.      3 ['attitude', 'wise', 'assumed']\n"
     ]
    }
   ],
   "source": [
    "for i, cluster in enumerate(clusters):\n",
    "    print(f'{str(i).rjust(2)}. {str(len(cluster)).rjust(6)} {cluster[:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b71cce-a20a-4be3-9a08-63374a76bd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1839fc18-8a27-4dc5-a979-c82df63e2b88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "essay_scoring",
   "language": "python",
   "name": "essay_scoring"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
